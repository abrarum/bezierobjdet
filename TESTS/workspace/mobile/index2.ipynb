{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reset -f\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from numpy.random import rand, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import bezier\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, UpSampling2D, ZeroPadding2D, Flatten, Conv1D, Conv2D, Conv3D, MaxPool2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Activation\n",
    "from keras.layers.merge import add, concatenate\n",
    "\n",
    "print('Using TensorFlow version', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = image_height = 400\n",
    "gridcell = 10\n",
    "\n",
    "image_root = './images/multi_lines/train/'\n",
    "image_labels = ['line']\n",
    "\n",
    "total_files = fnmatch.filter(os.listdir(image_root), '*.png')\n",
    "#print(total_files)\n",
    "\n",
    "df=pd.read_csv('./images/multi_lines/train.csv', sep=',',header=0)\n",
    "\n",
    "def image_read(fn):\n",
    "    link = os.path.join(image_root, fn)\n",
    "    image = Image.open(link).convert('RGB')\n",
    "    im = np.asarray(image)\n",
    "    return im\n",
    "\n",
    "\n",
    "def getInfo(fn):\n",
    "    image = image_read(fn+\".png\")\n",
    "    \n",
    "    rows = np.where(df.filename==fn)\n",
    "    \n",
    "    class_id = df[\"class\"][rows[0][0]]\n",
    "    coords = []\n",
    "    \n",
    "    for i in rows[0]:\n",
    "        c_id = []\n",
    "        c_coord = []\n",
    "        \n",
    "        c_coord.append(df.xmin[i])\n",
    "        c_coord.append(df.xmax[i])\n",
    "        #the Y coordinate axis in the annotations starts at bottom\n",
    "        #inverting\n",
    "        c_coord.append(image_height - df.ymin[i])\n",
    "        c_coord.append(image_height - df.ymax[i])\n",
    "        \n",
    "        coords.append(c_coord)\n",
    "        c_id = []\n",
    "    \n",
    "    return image, class_id, coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(image, pred_coords, norm=False):\n",
    "    figo = Figure(figsize=(2, 2))\n",
    "\n",
    "    canvas = FigureCanvasAgg(figo)\n",
    "\n",
    "    # plot\n",
    "    ax_r = figo.add_subplot()\n",
    "    if norm:\n",
    "        image *= 255.\n",
    "        image = image.astype(np.uint8)\n",
    "    ax_r.imshow(image)\n",
    "    \n",
    "    for i in pred_coords:\n",
    "        xmin, xmax, ymin, ymax = i\n",
    "        ax_r.plot([xmin, xmax], [ymin, ymax], 'r+', linestyle='dotted', label='prediction')\n",
    "    \n",
    "    ax_r.set_axis_off()\n",
    "\n",
    "    canvas.draw()\n",
    "\n",
    "    buf = canvas.buffer_rgba()\n",
    "    # ... convert to a NumPy array ...\n",
    "    X = np.asarray(buf)\n",
    "    # ... and pass it to PIL.\n",
    "    im = Image.fromarray(X)\n",
    "\n",
    "    return im\n",
    "\n",
    "def randlGen():\n",
    "    '''Returns a random image file name'''\n",
    "    rElem = np.random.choice(total_files)\n",
    "    rElem = rElem[0:-4]\n",
    "    return rElem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, class_id, pred_coords = getInfo(randlGen())\n",
    "\n",
    "image = plot_line(image, pred_coords,norm=False)\n",
    "plt.imshow(image)\n",
    "plt.title(\"line\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel gTruth and Line gTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAADoCAYAAADsUSLaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbpklEQVR4nO3df7DddX3n8ecrN7/5IUEuGJIgkY1gsGOwtxGlU12xgrbT4B92444u7drF2cUW2+644MxO2z8y2+62anem2qWVyrZWNoN0ZRlXpRR03FowYFRCQFJD4ZJIrhUBfxCSm/f+cb5Jzg33V3LPyTkneT5mztzv+Zzv93ve33vvm7z43s/5flNVSJIkSSe7eb0uQJIkSeoHBmNJkiQJg7EkSZIEGIwlSZIkwGAsSZIkAQZjSZIkCehiME5yZZJHkuxIcn233keSJEnqhHTjOsZJhoBvAz8PjAJfA95VVQ91/M0kSZKkDujWGeP1wI6q+k5VvQDcAmzo0ntJkiRJc9atYLwCeKLt+WgzJkmSJPWl+V3abyYZmzBnI8k1wDUAp5xyyk9fdNFFXSpFGjz333//96pquNd1TGVhFtViTul1GVLfeI6n+7Zn7Vdpoun6tVvBeBRY1fZ8JbCrfYWquhG4EWBkZKS2bNnSpVKkwZPkn3pdw3QWcwqvy+W9LkPqG39bt/Ztz9qv0kTT9Wu3plJ8DViTZHWShcBG4PYuvZckSZI0Z105Y1xV+5O8H/gCMATcVFXbuvFekiRJUid0ayoFVfU54HPd2r8kSZLUSd75TpIkScJgLAnvVCkNEvtV6h6DsXSSa+5U+SfA24C1wLuSrO1tVZImY79K3WUwluSdKqXBYb9KXWQwluSdKqXBYb9KXdS1q1JIGhgz3qkSJt6tcjFLu12TpMnZr1IXecZY0ox3qoTW3SqraqSqRhaw6LgVJ2kC+1XqIoOxJO9UKQ0O+1XqIqdSSCc571QpDQ77Veoug7Ek71QpDRD7Veoep1JIkiRJGIwlSZIkwGAsSZIkAQZjSZIkCTAYS5IkSYDBWJIkSQLmeLm2JI8BzwHjwP6qGklyJvC/gPOBx4Bfrqqn51amJEmS1F2dOGP8L6tqXVWNNM+vB+6qqjXAXc1zSZIkqa91YyrFBuDmZvlm4KouvIckSZLUUXMNxgV8Mcn9Sa5pxs6pqt0Azdez5/gekiRJUtfN9ZbQl1XVriRnA3cmeXi2GzZB+hqA8847b45lSJIkSXMzpzPGVbWr+boH+BtgPfBUkuUAzdc9U2x7Y1WNVNXI8PDwXMqQJEmS5uyYg3GSU5KcdnAZeCvwIHA7cHWz2tXAZ+dapCRJktRtc5lKcQ7wN0kO7uevq+rzSb4GbE7yXuBx4J1zL1OSJEnqrmMOxlX1HeA1k4z/M3D5XIqSJEmSjjfvfCdJkiRhMJYkSZIAg7EkSZIEGIwlSZIkwGAsSZIkAQZjSZIkCTAYS5IkSYDBWJIkSQIMxpIkSRJgMJYkSZIAg7EkSZIEGIwlSZIkwGAsSZIkAQZjSZIkCTAYS5IkScAsgnGSm5LsSfJg29iZSe5M8mjzdVnbazck2ZHkkSRXdKtwSZ2RZFWSu5NsT7ItyXW9rknS5OxXqbtmc8b4k8CVR4xdD9xVVWuAu5rnJFkLbAQubrb5WJKhjlUrqRv2A79dVa8CLgWubXpZUv+xX6UumjEYV9WXge8fMbwBuLlZvhm4qm38lqraW1U7gR3A+s6UKqkbqmp3VT3QLD8HbAdW9LYqSZOxX6XuOtY5xudU1W5oNSlwdjO+Aniibb1RbFhpYCQ5H7gEuLfHpUiagf0qdV6nP3yXScZq0hWTa5JsSbJlbGysw2VIOlpJTgU+A3ygqp6d5PVDPbuPvce/QEmH2K9SdxxrMH4qyXKA5uueZnwUWNW23kpg12Q7qKobq2qkqkaGh4ePsQxJnZBkAa1/ZD9VVbdNtk57zy5g0fEtUNIh9qvUPccajG8Hrm6WrwY+2za+McmiJKuBNcB9cytRUjclCfAJYHtVfbjX9Uiamv0qdddsLtf2aeCrwIVJRpO8F/h94OeTPAr8fPOcqtoGbAYeAj4PXFtV490qXlJHXAa8B3hzkq3N4+29LkrSpOxXqYvmz7RCVb1ripcun2L9TcCmuRQl6fipqq8w+ecDJPUZ+1XqLu98J0mSJGEwliRJkgCDsSRJkgQYjCVJkiTAYCxJkiQBBmNJkiQJMBhLkiRJgMFYkiRJAgzGkiRJEmAwliRJkgCDsSRJkgQYjCVJkiTAYCxJkiQBBmNJkiQJMBhLkiRJgMFYkiRJAmYRjJPclGRPkgfbxn43yZNJtjaPt7e9dkOSHUkeSXJFtwqXJEmSOmk2Z4w/CVw5yfhHqmpd8/gcQJK1wEbg4mabjyUZ6lSxkiRJUrfMGIyr6svA92e5vw3ALVW1t6p2AjuA9XOoT5IkSTou5jLH+P1JvtlMtVjWjK0AnmhbZ7QZkyRJkvrasQbjjwMXAOuA3cAfNeOZZN2abAdJrkmyJcmWsbGxYyxDkiRJ6oxjCsZV9VRVjVfVAeDPODxdYhRY1bbqSmDXFPu4sapGqmpkeHj4WMqQJEmSOuaYgnGS5W1P3wEcvGLF7cDGJIuSrAbWAPfNrURJkiSp++bPtEKSTwNvAs5KMgr8DvCmJOtoTZN4DHgfQFVtS7IZeAjYD1xbVeNdqVySJEnqoBmDcVW9a5LhT0yz/iZg01yKkiRJko4373wnSZIkYTCWJEmSAIOxJEmSBBiMJUmSJMBgLEmSJAEGY0mSJAkwGEtqJBlK8vUkd/S6FknTs1+l7jAYSzroOmB7r4uQNCv2q9QFBmNJJFkJ/ALw572uRdL07FepewzGkgA+CnwQODDVCkmuSbIlyZZ97D1uhUl6kY9iv0pdYTCWTnJJfhHYU1X3T7deVd1YVSNVNbKARcepOknt7FepuwzGki4DfinJY8AtwJuT/FVvS5I0BftV6iKDsXSSq6obqmplVZ0PbAT+rqre3eOyJE3CfpW6y2AsSZIkAfN7XYCk/lFV9wD39LgMSbNgv0qd5xljSZIkiVkE4ySrktydZHuSbUmua8bPTHJnkkebr8vatrkhyY4kjyS5opsHIEmSJHXCbM4Y7wd+u6peBVwKXJtkLXA9cFdVrQHuap7TvLYRuBi4EvhYkqFuFC9JkiR1yozBuKp2V9UDzfJztG5BuQLYANzcrHYzcFWzvAG4par2VtVOYAewvsN1S5IkSR11VHOMk5wPXALcC5xTVbuhFZ6Bs5vVVgBPtG022oxJkiRJfWvWwTjJqcBngA9U1bPTrTrJWE2yv0O3qxwbG5ttGZIkSVJXzCoYJ1lAKxR/qqpua4afSrK8eX05sKcZHwVWtW2+Eth15D7bb1c5PDx8rPVLkiRJHTGbq1IE+ASwvao+3PbS7cDVzfLVwGfbxjcmWZRkNbAGuK9zJUuSJEmdN5sbfFwGvAf4VpKtzdiHgN8HNid5L/A48E6AqtqWZDPwEK0rWlxbVeOdLlySJEnqpBmDcVV9hcnnDQNcPsU2m4BNc6hLkiRJOq68850kSZKEwViSJEkCDMaSJEkSYDCWJEmSAIOxJEmSBBiMJUmSJMBgLEmSJAEGY0mSJAkwGEuSJEmAwViSJEkCDMaSJEkSYDCWJEmSAIOxJEmSBBiMJUmSJMBgLEmSJAGzCMZJViW5O8n2JNuSXNeM/26SJ5NsbR5vb9vmhiQ7kjyS5IpuHoAkSZLUCfNnsc5+4Ler6oEkpwH3J7mzee0jVfWH7SsnWQtsBC4GzgX+Nskrq2q8k4VLkiRJnTTjGeOq2l1VDzTLzwHbgRXTbLIBuKWq9lbVTmAHsL4TxUqSJEndclRzjJOcD1wC3NsMvT/JN5PclGRZM7YCeKJts1GmD9KSJElSz806GCc5FfgM8IGqehb4OHABsA7YDfzRwVUn2bwm2d81SbYk2TI2Nna0dUuSJEkdNatgnGQBrVD8qaq6DaCqnqqq8ao6APwZh6dLjAKr2jZfCew6cp9VdWNVjVTVyPDw8FyOQdIcJTkjya1JHm4+aPv6XtckaXL2q9Q9s7kqRYBPANur6sNt48vbVnsH8GCzfDuwMcmiJKuBNcB9nStZUhf8MfD5qroIeA2tzxJI6k/2q9Qls7kqxWXAe4BvJdnajH0IeFeSdbSmSTwGvA+gqrYl2Qw8ROuKFtd6RQqpfyU5Hfg54FcAquoF4IVe1iRpcvar1F0zBuOq+gqTzxv+3DTbbAI2zaEuScfPK4Ax4C+SvAa4H7iuqn7U27IkTcJ+lbrIO99Jmg+8Fvh4VV0C/Ai4/siV2j8wu4+9x7tGSS32q9RFBmNJo8BoVR28DOOttP7hnaD9A7MLWHRcC5R0iP0qdZHBWDrJVdV3gSeSXNgMXU7rMwKS+oz9KnXXbD58J+nE9+vAp5IsBL4D/GqP65E0NftV6hKDsSSqaisw0us6JM3MfpW6x6kUkiRJEgZjSZIkCTAYS5IkSYDBWJIkSQIMxpIkSRLgVSkkaVpf2LW1o/u74tx1Hd2fpMPsV82VZ4wlSZIkDMaSJEkSYDCWJEmSAIOxJEmSBBiMJUmSJGAWwTjJ4iT3JflGkm1Jfq8ZPzPJnUkebb4ua9vmhiQ7kjyS5IpuHoAkSZLUCbM5Y7wXeHNVvQZYB1yZ5FLgeuCuqloD3NU8J8laYCNwMXAl8LEkQ12oXZIkSeqYGYNxtfywebqgeRSwAbi5Gb8ZuKpZ3gDcUlV7q2onsANY38miJUmSpE6b1RzjJENJtgJ7gDur6l7gnKraDdB8PbtZfQXwRNvmo82YJEmS1LdmFYyraryq1gErgfVJXj3N6plsFy9aKbkmyZYkW8bGxmZVrCRJktQtR3VViqr6AXAPrbnDTyVZDtB83dOsNgqsattsJbBrkn3dWFUjVTUyPDx89JVLkiRJHTSbq1IMJzmjWV4CvAV4GLgduLpZ7Wrgs83y7cDGJIuSrAbWAPd1uG5JkiSpo+bPYp3lwM3NlSXmAZur6o4kXwU2J3kv8DjwToCq2pZkM/AQsB+4tqrGu1O+JEmS1BkzBuOq+iZwySTj/wxcPsU2m4BNc65OkiRJOk5mc8a4577++NPs+sFPDj1/yZKFXHrBmdNuE8K8QDLZZwElSZKkiQYiGP/lP/wTn916+PN7SxYMcd6ZSw89L4rxAxMvfJGEfzWyipeeunDK/S4YmscbXznMovnTT7UemhcDtiRJ0gluIILxB6+4iP/wpgumfH306Z9MCM4HfevJZw4tH6jinkfG+PEL+w+NzUs478ylDM07HHr3j9eEa8udsXQBG39m1YR1JvOGC17KmacsmvL1BOYbsCVJkvrWQATjl71kMbB4ytf/xdmn8aYLz57ydYCqYvTpn7Bv/MCU6/z4hXE+fd/jvLB/4jr37fz+hOf37vw+333m+Qljy89YzOIFh+98vW/8ANWWsOclbPyZVbxk6YJp61y7/HTWnHPqtOssmDePeTMEdUmSJB2dgQjGnZCEVW3TL6ay6R0/NeM6e559nh+/MPWFNgr4zAOjfO+5vRPG/3Hsh4eW9x8o7nzoKZ7fN3E/y5Yu5PQlh38s+8eL8Zo4TeSKi1/G6rNOmfL9A7zxwmGWLZ16Ggm0pogsGDqqS1lLkiSdsE6aYNxJZ58+9dnrg/7jWy+c9vUDVex+5vkXzY0+0pe/Pcb23c9OGPvR3v082DZN5CuPfo+nnpt4BvucLy1mYVvoHT9QLzpb/lMrX8IbLjhr2vdft+oMLhie/gz2vMDC+fOcJqJj9oVdWzu2ryvOXdexfXVjf9KgG3rVmo7ta3z7ox3bF9ivmjuDcY/MS1hxxpIZ13v3pS+fcZ3v/XAve/dNPUUE4NE9z3H3Iy++9fajew6fxd725DM8dEQIf8mSBZyy6PCvyQv7D7D/wMT3Ouf0xWx4zbnTvv95L13K61a/dNp1FgzNY+EMH4SUJEnqlsEPxt/fCbsegLVXwbyhGVc/EZ116tQf+jtoxbIlM87Dfu75ffxw7/5p17n74bEJU0IOeuLpw5fT++4zz3PPt/dMeH3JgiHOWHJ4ase+AwdeFOYvOe8MfvrlyyZ9359dcxYXvez0aWuTJEmai8EPxg/fAXdvglNfBudf1utqBtppixdw2uLpPxz4r1933oz72bt/nB/8eN+06zy8+zn+/h+/96LxsbZ52T9+YZw7vrmL/QeKZUsXGowlSVJXDX4wft374NEvwv/9IPzy/4SXTn1ZNx0fi+YPcc7p05+9P+f0xbzxwuFp1xk/UFz3ljVUwWmLB/9XVZIk9bfBn9A5tBDe9gfw/A/gCx+C8emnAmhwDM0LZ526iOHTFk24FJ46L8lvJtmW5MEkn04y8ydMJfWE/Sp1z+AHY4DhV8Frr4adX4K//2MYn/7P+JIOS7IC+A1gpKpeDQwBG3tblaTJ2K9Sd50Yf59O4Gd/E/b9GO75L/DyN8B5r+91VdIgmQ8sSbIPWAq8+FaSkvqF/Sp1yYlxxhhgaAH89K/Ama+AO34Lnt3d64qkgVBVTwJ/CDwO7Aaeqaov9rYqSZOxX6XuOnGCMcAZL4df/kt4/ll44GanVEizkGQZsAFYDZwLnJLk3ZOsd02SLUm27GPvkS9LOg7sV6m7TqxgnMBZr4SRX4X/98dw7//odUXSIHgLsLOqxqpqH3Ab8IYjV6qqG6tqpKpGFjDztbMldYX9KnXRjME4yeIk9yX5RvMp2N9rxn83yZNJtjaPt7dtc0OSHUkeSXJFNw9gkoLhZz/Quozblptg7JHj+vbSAHocuDTJ0rTu6305sL3HNUmanP0qddFszhjvBd5cVa8B1gFXJrm0ee0jVbWueXwOIMlaWp+QvRi4EvhYkuN7ra1581tXqZi/CDb/G3juu8f17aVBUlX3ArcCDwDfovXfhRt7WpSkSdmvUnfNGIyr5eA9gBc0j5pmkw3ALVW1t6p2AjuA9XOu9GgtOx/e/J/h6Z2tM8fjLxz3EqRBUVW/U1UXVdWrq+o9VeWkRKlP2a9S98xqjnGSoSRbgT3Anc3/sQK8P8k3k9zUfCAAYAXwRNvmo83Ykfs89MGAsbGxYz+CqYuGV74Vfu6D8NU/gV3f6Px7SJIk6YQxq2BcVeNVtQ5YCaxP8mrg48AFtKZX7Ab+qFk9k+1ikn0e+mDA8PD0twY+ZvPmw2W/AS/7Kfjf/x72OA1LkiRJkzuqq1JU1Q+Ae4Arq+qpJjAfAP6Mw9MlRoFVbZutpJcXH5+3AK76WGu+8Zf+wCkVkiRJmtRsrkoxnOSMZnkJrUvFPJxkedtq7wAebJZvBzYmWZRkNbAGuK+jVR+NBJathjf+J/j25+FL/81wLEmSpBeZzS2hlwM3N1eWmAdsrqo7kvxlknW0pkk8BrwPoKq2JdkMPATsB66tqvFuFD9rCVz0C/AzvwZ//9/hwrfBitf2tCRJkiT1lxmDcVV9E7hkkvH3TLPNJmDT3ErrsHlDMPJe+M49cNu/a90h75y1va5KEnDFuet6XYKkWRrf/mivS5C65sS6891Mlp0P7/wk/ORp+MpHnFIhSZKkQ06uYHxwvvFl18HD/wfu/2SvK5IkSVKfmM0c4xPLvCF4/ftbd8P7hz+Fl18GZ69thWZJkiSdtE6uM8YHzRuC9dfAwqVw67+Fvc/2uiJJkiT12MkZjAHOXN36AN65lzD5PUkkSZJ0Mjn5plK0O3M1vONPe12FJEmS+sDJe8ZYkiRJamMwliRJkjAYS5IkSYDBWJIkSQIMxpIkSRJgMJYkSZIAg7EkSZIEGIwlSZIkwGAsSZIkAQZjSZIkCTAYS5IkSYDBWJIkSQIMxpIkSRIAqape10CSMeBHwPd6XcscnYXH0A9OhGN4eVUN97qIqTQ9+0+zWLWffxbWduz6ub5e1da3PWu/Hhf9XJ+1vdiU/doXwRggyZaqGul1HXPhMfSHE+EYThT9/LOwtmPXz/X1c239rp+/d/1cG/R3fdZ2dJxKIUmSJGEwliRJkoD+CsY39rqADvAY+sOJcAwnin7+WVjbsevn+vq5tn7Xz9+7fq4N+rs+azsKfTPHWJIkSeqlfjpjLEmSJPVMz4NxkiuTPJJkR5Lre13PVJLclGRPkgfbxs5McmeSR5uvy9peu6E5pkeSXNGbqidKsirJ3Um2J9mW5LpmfGCOI8niJPcl+UZzDL/XjA/MMZwM+rWvp+qBfpNkKMnXk9zR61raJTkjya1JHm6+h6/vdU0HJfnN5mf6YJJPJ1nc65oGRb/2KwxGz/Zrv4I9e0yqqmcPYAj4R+AVwELgG8DaXtY0Ta0/B7wWeLBt7L8C1zfL1wN/0CyvbY5lEbC6OcahPjiG5cBrm+XTgG83tQ7McQABTm2WFwD3ApcO0jGc6I9+7uupeqDXdU1S528Bfw3c0etajqjrZuDXmuWFwBm9rqmpZQWwE1jSPN8M/Eqv6xqERz/3a1Nf3/dsv/ZrU5s9e5SPXp8xXg/sqKrvVNULwC3Ahh7XNKmq+jLw/SOGN9D6paP5elXb+C1VtbeqdgI7aB1rT1XV7qp6oFl+DthO65dzYI6jWn7YPF3QPIoBOoaTQN/29TQ90DeSrAR+AfjzXtfSLsnptE4QfAKgql6oqh/0tKiJ5gNLkswHlgK7elzPoOjbfoX+79l+7VewZ49Vr4PxCuCJtuej9NEv/CycU1W7odW8wNnNeN8fV5LzgUtonXEdqONo/my1FdgD3FlVA3cMJ7iB+J4f0QP95KPAB4EDPa7jSK8AxoC/aP5s/OdJTul1UQBV9STwh8DjwG7gmar6Ym+rGhgD0a/Qtz37UfqzX8GePSa9DsaZZOxEuExGXx9XklOBzwAfqKpnp1t1krGeH0dVjVfVOmAlsD7Jq6dZvS+P4QTX99/zo+iB4yrJLwJ7qur+Xtcyifm0ppN9vKouAX5Ea9pSzzWfKdhAa7rUucApSd7d26oGRt/3K/Rnz/Z5v4I9e0x6HYxHgVVtz1fSJ6fSZ+mpJMsBmq97mvG+Pa4kC2j9x+VTVXVbMzxwxwHQ/EnoHuBKBvQYTlB9/T2fogf6xWXALyV5jNaftN+c5K96W9Iho8Bo8xcagFtp/aPbD94C7KyqsaraB9wGvKHHNQ2Kvu5X6Oue7ed+BXv2mPQ6GH8NWJNkdZKFwEbg9h7XdDRuB65ulq8GPts2vjHJoiSrgTXAfT2ob4IkoTXXaHtVfbjtpYE5jiTDSc5olpfQaq6HGaBjOAn0bV9P0wN9oapuqKqVVXU+re/b31VVX5xFqarvAk8kubAZuhx4qIcltXscuDTJ0uZnfDmtuaiaWd/2K/R3z/Zzv4I9e6zm9/LNq2p/kvcDX6D1ydibqmpbL2uaSpJPA28CzkoyCvwO8PvA5iTvpfVDfidAVW1LspnWL+B+4NqqGu9J4RNdBrwH+FYzRxfgQwzWcSwHbk4yROt/7DZX1R1JvsrgHMMJrc/7etIeqKrP9a6kgfLrwKeaAPUd4Fd7XA8AVXVvkluBB2j1+dfpwztq9aM+71ewZ+fKnj1K3vlOkiRJovdTKSRJkqS+YDCWJEmSMBhLkiRJgMFYkiRJAgzGkiRJEmAwliRJkgCDsSRJkgQYjCVJkiQA/j8RqfqLKywALAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def linear(coord):\n",
    "    '''Converts coordinates from scale `image_height`x`image_width`\n",
    "       to scale `gridcell`x`gridcell` '''\n",
    "    n_a = []\n",
    "    \n",
    "    for i in coord:\n",
    "        OldValue = i\n",
    "        OldMax = image_width-1\n",
    "        OldMin = 0\n",
    "        NewMax = gridcell-1\n",
    "        NewMin = 0\n",
    "        OldRange = (OldMax - OldMin)  \n",
    "        NewRange = (NewMax - NewMin)  \n",
    "        x = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
    "        n_a.append(x)\n",
    "    \n",
    "    return np.asarray(n_a)\n",
    "\n",
    "def midPoint(p12):\n",
    "    x1, x2, y1, y2 = p12\n",
    "    \n",
    "    x = (x1 + x2)/2\n",
    "    y = (y1 + y2)/2\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "def gtruther(index):\n",
    "\n",
    "    image, class_id, coords = getInfo(index)\n",
    "    \n",
    "    #truther shapes\n",
    "    pxTruth = np.zeros((gridcell,gridcell,1))\n",
    "    liTruth = np.zeros((gridcell,gridcell,4))\n",
    "    mps = []\n",
    "    \n",
    "    if (class_id == 1):\n",
    "        for i in coords:\n",
    "            x1, x2, y1, y2 = i\n",
    "            \n",
    "            #mapping\n",
    "            p12 = linear(i)\n",
    "\n",
    "            #find mp\n",
    "            mp = midPoint(p12)\n",
    "            mp = np.around(mp)\n",
    "            \n",
    "            #mp coords\n",
    "            #y, x = mp.astype(int)\n",
    "            x, y = mp.astype(int) #x,y same order as in `i`\n",
    "\n",
    "            #line coords\n",
    "            x1, x2, y1, y2 = p12\n",
    "\n",
    "            #allot line gt coords of mp coords to liTruth shape\n",
    "            liTruth[y][x] = i\n",
    "            pxTruth[y][x] = [class_id]\n",
    "            mps.append([y,x])\n",
    "            \n",
    "\n",
    "    return image, liTruth, pxTruth, class_id, mps\n",
    "\n",
    "\n",
    "def test_sbs(index):\n",
    "    image, class_id, coords = getInfo(index)\n",
    "    pimg, liTruth, pxTruth, class_id, mps = gtruther(index)\n",
    "    \n",
    "    plt.figure(0, (12,8))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    #plt.tight_layout(pad=0)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(pxTruth)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(liTruth[...,1])\n",
    "    \n",
    "test_sbs(\"li_213\")\n",
    "#test_sbs(\"li_410\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# DATA GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def regression_weight_map(cls_target):\n",
    "    '''Creates a weight map for the regression target.\n",
    "       The weight map is 1.0 where the classification target is not zero.\n",
    "       Shape=(B,H,W)  (no channel dimension as required by the loss functions)'''\n",
    "    return (cls_target[...,0] > 0).astype('float32')\n",
    "\n",
    "def data_generator(batch_size=batch_size):\n",
    "    while True:\n",
    "        x_batch = np.zeros((batch_size, image_height, image_width, 3))\n",
    "        y_batch = np.zeros((batch_size, gridcell, gridcell, 1))\n",
    "        bline_batch   = np.zeros((batch_size, gridcell, gridcell, 4))\n",
    "\n",
    "        for i,j in enumerate(total_files[0:batch_size]):\n",
    "            image, liTruth, pxTruth, class_id, mps = gtruther(randlGen())\n",
    "            \n",
    "            x_batch[i] = image / 255.\n",
    "            y_batch[i] = pxTruth\n",
    "            bline_batch[i] = liTruth\n",
    "            \n",
    "        sample_weight = regression_weight_map(y_batch)\n",
    "        yield ({'image': x_batch}, {'class_out': y_batch, 'line_out': bline_batch}, {'line_out': sample_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(class_id, pred_coords):\n",
    "    #for label\n",
    "    count = 0\n",
    "    pos = []\n",
    "    coords = []\n",
    "\n",
    "    #gT label\n",
    "    for i,j in enumerate(class_id):\n",
    "        for k,l in enumerate(class_id):\n",
    "            if(class_id[i][k] >= 1):\n",
    "                pos.append([i,k])\n",
    "                count = count + 1\n",
    "\n",
    "    for i,j in enumerate(pred_coords):\n",
    "        for k,l in enumerate(pred_coords):\n",
    "            if (all(i != 0 for i in pred_coords[i][k])):\n",
    "                coords.append(pred_coords[i][k])\n",
    "\n",
    "    return count, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def testerxo():\n",
    "    index = 95\n",
    "    example, label, sample_weight = next(data_generator(100))\n",
    "    image = example['image'][index]\n",
    "    class_id = label['class_out'][index]\n",
    "    pred_coords = label['line_out'][index]\n",
    "\n",
    "    count, coords = extractor(class_id, pred_coords)\n",
    "    print(count)\n",
    "    image = plot_line(image, coords, norm=True)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.title('line')\n",
    "    plt.show()\n",
    "\n",
    "testerxo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, 400, 400, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 398, 398, 16) 448         image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 398, 398, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 199, 199, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 197, 197, 32) 4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 197, 197, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 98, 98, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 96, 96, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 48, 48, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 46, 46, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 46, 46, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 23, 23, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 21, 21, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 21, 21, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "class_out (Conv2D)              (None, 10, 10, 1)    257         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "line_out (Conv2D)               (None, 10, 10, 4)    1028        max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 395,877\n",
      "Trainable params: 394,885\n",
      "Non-trainable params: 992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def modelTester():\n",
    "    input_ = Input(shape=(image_height, image_width, 3), name='image')\n",
    "\n",
    "    x = input_\n",
    "\n",
    "    for i in range(0, 5):\n",
    "      n_filters = 2**(4 + i)\n",
    "      x = Conv2D(n_filters, 3, activation='relu')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = MaxPool2D(2)(x)\n",
    "    \n",
    "    x1 = Conv2D(1, (1,1), name=\"class_out\")(x)\n",
    "    x2 = Conv2D(4, (1,1), name=\"line_out\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(input_, [x1,x2])\n",
    "    model.summary()\n",
    "    return model\n",
    "    \n",
    "model = modelTester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    h, w = image_height, image_width\n",
    "    \n",
    "    backbone = keras.applications.MobileNet(input_shape=(h,w,3), include_top=False)\n",
    "    \n",
    "    x = x0   = keras.Input(shape=(h,w,3), name='image')\n",
    "    x        = backbone(x)\n",
    "    \n",
    "    x1 = Conv2D(1, (1,1), name=\"class_out\")(x)\n",
    "    x2 = Conv2D(4, (1,1), name=\"line_out\")(x)\n",
    "    model    = keras.Model(inputs=x0, outputs=[x1,x2])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#model = model1()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss={\n",
    "        #from_logits=True if class_out has no activation function\n",
    "        #from_logits=False if class_out has sigmoid activation\n",
    "        'class_out': keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        'line_out': 'mse'\n",
    "    },\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics={\n",
    "        'class_out': 'accuracy',\n",
    "        'line_out': [tf.keras.metrics.MeanAbsoluteError()]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_datagen):\n",
    "\n",
    "    example, label, sample_weight = next(test_datagen)\n",
    "\n",
    "    image = example['image']\n",
    "    class_id = label['class_out']\n",
    "\n",
    "    #gtruth lines\n",
    "    coords = label['line_out']\n",
    "    gtcount, gtcoords = extractor(class_id[0], coords[0])\n",
    "\n",
    "    #predicted lines\n",
    "    pred_class, pred_line = model.predict(image)\n",
    "    pred_count, pred_coords = extractor(pred_class[0], pred_line[0])\n",
    "    \n",
    "    #class_id\n",
    "    gt = 0 if gtcount < 1 else 1\n",
    "    pred_class_name = 0 if pred_count < 1 else 1\n",
    "    \n",
    "    print(\"pred_class\", pred_class)\n",
    "\n",
    "    image = plot_line(image[0], pred_coords)\n",
    "\n",
    "    color = 'green' if gt == pred_class_name else 'red'\n",
    "\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.xlabel(f'Pred: {pred_class_name}', color=color)\n",
    "    plt.ylabel(f'GT: {gt}', color=color)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    test_datagen = data_generator(1)\n",
    "\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        plt.subplot(1, 6, i + 1)\n",
    "        test_model(model, test_datagen)\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv2d/Relu (defined at <ipython-input-11-aa6a1194e610>:13) ]] [Op:__inference_predict_function_574]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5bfdcc797401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-7da902b440fa>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_datagen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-aa6a1194e610>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_datagen)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#predicted lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpred_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mpred_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m               *args, **kwds)\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[1;32m    895\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv2d/Relu (defined at <ipython-input-11-aa6a1194e610>:13) ]] [Op:__inference_predict_function_574]\n\nFunction call stack:\npredict_function\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowTestImages(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    test(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;0a57fad172d1613a;/job:localhost/replica:0/task:0/device:GPU:0;edge_43_IteratorGetNext;0:0\n\t [[{{node IteratorGetNext/_2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_2156]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8e90581c9eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m _ = model.fit(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;0a57fad172d1613a;/job:localhost/replica:0/task:0/device:GPU:0;edge_43_IteratorGetNext;0:0\n\t [[{{node IteratorGetNext/_2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_2156]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    lr *= 0.2\n",
    "  return max(lr, 3e-7)\n",
    "\n",
    "\n",
    "_ = model.fit(\n",
    "    data_generator(batch_size=100),\n",
    "    use_multiprocessing=True,\n",
    "    workers=24,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=len(total_files) / batch_size,\n",
    "    callbacks=[\n",
    "               #ShowTestImages(),\n",
    "               #tf.keras.callbacks.EarlyStopping(monitor='line_out_mean_absolute_error', patience=3, mode='max'),\n",
    "               tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Outputs after a few epochs training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x,_y,_ = next(iter(data_generator()))\n",
    "_out_cls, _out_reg = model.predict(_x['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "plt.figure(0, (16,16))\n",
    "for i,j in enumerate([3,6,10]):\n",
    "    plt.subplot(3,3,i+1);   plt.imshow(_x['image'][j])\n",
    "    plt.subplot(3,3,i+1+3); plt.imshow(_y['class_out'][j])\n",
    "    plt.subplot(3,3,i+1+6); plt.imshow(_out_cls[j])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Object Localization with TensorFlow - Starter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
