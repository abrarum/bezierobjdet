{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reset -f\n",
    "\n",
    "'''\n",
    "gpu = 3\n",
    "from numba import cuda\n",
    "cuda.close()\n",
    "cuda.select_device(gpu)\n",
    "#cuda.close()\n",
    "'''\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import tensorflow as tf\n",
    "#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:2\", \"/gpu:3\"])\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from numpy.random import rand, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import bezier\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, UpSampling2D, ZeroPadding2D, Flatten, Conv1D, Conv2D, Conv3D, MaxPool2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Activation\n",
    "from keras.layers.merge import add, concatenate\n",
    "\n",
    "print('Using TensorFlow version', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 648x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 9))\n",
    "image_width = image_height = 400\n",
    "gridcell = 10\n",
    "\n",
    "image_root = './images/multi_lines/train/'\n",
    "image_labels = ['line']\n",
    "\n",
    "total_files = fnmatch.filter(os.listdir(image_root), '*.png')\n",
    "#print(total_files)\n",
    "\n",
    "df=pd.read_csv('./images/multi_lines/train.csv', sep=',',header=0)\n",
    "\n",
    "def image_read(fn):\n",
    "    link = os.path.join(image_root, fn)\n",
    "    image = Image.open(link).convert('RGB')\n",
    "    im = np.asarray(image)\n",
    "    #print(im.shape)\n",
    "    return im\n",
    "    \n",
    "def generate_bezier(x, y):\n",
    "    nr = np.asarray(x, y)\n",
    "    curve = bezier.Curve(nr, degree=1)\n",
    "    \n",
    "    return curve\n",
    "\n",
    "def gen_plots():\n",
    "    for i in range(9):\n",
    "        rand_idx = randint(0, len(total_files))\n",
    "        image, class_id, x, y = getInfo(rand_idx)\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        \n",
    "        l1 = ax.imshow(image, extent=[0, image_height, 0, image_width])\n",
    "        l1.set_label(\"\")\n",
    "        \n",
    "        # Create bezier curve or plot a line\n",
    "        '''\n",
    "        curve = generate_bezier(x, y)\n",
    "        g_truth = curve.plot(num_pts=256, color=\"r\", ax=ax)\n",
    "        g_truth.lines[-1].set_label('prediction var 1')\n",
    "        g_truth.lines[-1].set_linestyle('dotted')\n",
    "        g_truth.lines[-1].set_marker('+')\n",
    "        g_truth.lines[-1].set_markersize(2)\n",
    "        '''\n",
    "        \n",
    "        ax.plot(x, y, 'r+', linestyle='dotted', label='prediction')\n",
    "        \n",
    "        lines, labels = ax.get_legend_handles_labels()\n",
    "        plt.legend( lines, labels, loc = 'best', bbox_to_anchor = (0,-0.1,1,1),\n",
    "                    bbox_transform = plt.gcf().transFigure )\n",
    "        \n",
    "        plt.xlabel(image_labels[0])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "#gen_plots()\n",
    "\n",
    "\n",
    "def getInfo(fn):\n",
    "    #print(fn)\n",
    "    image = image_read(fn+\".png\")\n",
    "    \n",
    "    rows = np.where(df.filename==fn)\n",
    "    \n",
    "    class_id = df[\"class\"][rows[0][0]]\n",
    "    coords = []\n",
    "    \n",
    "    for i in rows[0]:\n",
    "        c_id = []\n",
    "        c_coord = []\n",
    "        \n",
    "        c_coord.append(df.xmin[i])\n",
    "        c_coord.append(df.xmax[i])\n",
    "        c_coord.append(df.ymin[i])\n",
    "        c_coord.append(df.ymax[i])\n",
    "        \n",
    "        coords.append(c_coord)\n",
    "        c_id = []\n",
    "    \n",
    "    return image, class_id, coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tester():\n",
    "    rand_idx = randint(0, len(total_files))\n",
    "    image, class_id, x, y = getInfo(rand_idx)\n",
    "    return image\n",
    "\n",
    "def plot_line(image, pred_coords, norm=False):\n",
    "    figo = Figure(figsize=(2, 2))\n",
    "\n",
    "    canvas = FigureCanvasAgg(figo)\n",
    "\n",
    "    # plot\n",
    "    ax_r = figo.add_subplot()\n",
    "    if norm:\n",
    "        image *= 255.\n",
    "        image = image.astype(np.uint8)\n",
    "    ax_r.imshow(image, extent=[0,image_height,0,image_width])\n",
    "    \n",
    "    for i in pred_coords:\n",
    "        xmin, xmax, ymin, ymax = i\n",
    "        ax_r.plot([xmin, xmax], [ymin, ymax], 'r+', linestyle='dotted', label='prediction')\n",
    "    \n",
    "    '''\n",
    "    if len(pred_coords) == 2:\n",
    "        x, y = pred_coords\n",
    "        #print(x, y)\n",
    "        xmin = x[0]\n",
    "        xmax = x[1]\n",
    "        ymin = y[0]\n",
    "        ymax = y[1]\n",
    "        ax_r.plot([xmin, xmax], [ymin, ymax], 'r+', linestyle='dotted', label='prediction')\n",
    "    '''\n",
    "    ax_r.set_axis_off()\n",
    "\n",
    "    canvas.draw()\n",
    "\n",
    "    buf = canvas.buffer_rgba()\n",
    "    # ... convert to a NumPy array ...\n",
    "    X = np.asarray(buf)\n",
    "    # ... and pass it to PIL.\n",
    "    im = Image.fromarray(X)\n",
    "\n",
    "    return im\n",
    "\n",
    "def randlGen():\n",
    "    rElem = np.random.choice(total_files)\n",
    "    rElem = rElem[0:-4]\n",
    "    return rElem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#rand_idx = randint(0, len(total_files))\n",
    "\n",
    "image, class_id, pred_coords = getInfo(randlGen())\n",
    "\n",
    "image = plot_line(image, pred_coords,norm=False)\n",
    "plt.imshow(np.flipud(image))\n",
    "plt.title(\"line\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truth pixels with testing (DISBANDED!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef test_sbs(index, method):\\n    image, class_id, x, y = getInfo(index)\\n    pimg = method(index, False)\\n    \\n    plt.subplot(1, 2, 1)\\n    plt.imshow(image)\\n    plt.subplot(1, 2, 2)\\n    plt.imshow(pimg)\\n    \\n    plt.subplot(121)\\n    plt.plot(image)\\n    plt.subplot(121)\\n    plt.plot(pimg)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def gtDistance1(index, test):\n",
    "    \n",
    "    threshold = 0.01\n",
    "    image, class_id, p1, p2 = getInfo(index)\n",
    "\n",
    "    gTruth = np.zeros((h,w,1))\n",
    "    \n",
    "    p1 = np.asarray([x / image_height for x in p1])\n",
    "    p2 = np.asarray([x / image_width for x in p2])\n",
    "    \n",
    "    #print(p1)\n",
    "    \n",
    "    for i,j in enumerate(image):\n",
    "        for k,l in enumerate(image):\n",
    "            x1 = i/h \n",
    "            x2 = k/w\n",
    "            p3 = np.asarray([x1,x2])\n",
    "            \n",
    "            dis = np.abs(np.cross(p2-p1, p1-p3)) / np.linalg.norm(p2-p1)\n",
    "            #print(dis)\n",
    "            if(test != True):\n",
    "                if (dis <= threshold):\n",
    "                    gTruth[i][k] = 1\n",
    "                else:\n",
    "                    gTruth[i][k] = 0\n",
    "            else:\n",
    "                if (dis <= threshold):\n",
    "                    gTruth[i][k] = 0\n",
    "                else:\n",
    "                    gTruth[i][k] = 255\n",
    "    #print(gTruth)\n",
    "    return gTruth\n",
    "\n",
    "\n",
    "def gtNaive(index):\n",
    "    image, class_id, x, y = getInfo(index)\n",
    "    # Naive non-generalized method\n",
    "    \n",
    "    gTruth = np.zeros((h,w,1))\n",
    "    #x[0][0] = [2]\n",
    "    \n",
    "    for i,j in enumerate(image):\n",
    "        for k,l in enumerate(image):\n",
    "            if (np.all(image[i][k] == 255)):\n",
    "                gTruth[i][k] = 0\n",
    "            else:\n",
    "                gTruth[i][k] = 255\n",
    "    return [image,gTruth]\n",
    "\n",
    "#gtNaive(1)\n",
    "\n",
    "#test_sbs(311, gtDistance2)\n",
    "\n",
    "'''\n",
    "x, y = gtNaive(103)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(y)\n",
    "'''\n",
    "'''\n",
    "def linear(coord):\n",
    "    \n",
    "    n_a = []\n",
    "    \n",
    "    for i in coord:\n",
    "        OldValue = i\n",
    "        OldMax = 143\n",
    "        OldMin = 0\n",
    "        NewMax = 17\n",
    "        NewMin = 0\n",
    "        OldRange = (OldMax - OldMin)  \n",
    "        NewRange = (NewMax - NewMin)  \n",
    "        x = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
    "        n_a.append(x)\n",
    "    \n",
    "    return np.asarray(n_a)\n",
    "'''\n",
    "def gtDistance2(index, test):\n",
    "    \n",
    "    threshold = 1\n",
    "    image_orig, class_id, p1, p2 = getInfo(index)\n",
    "    image = image_orig.reshape((1,image_height,image_width,3))\n",
    "    \n",
    "    gTruth = np.zeros((gridcell,gridcell,1))\n",
    "    \n",
    "    y = tf.image.extract_patches(images=image,\n",
    "                           sizes=[1, 8, 8, 1],\n",
    "                           strides=[1, 8, 8, 1],\n",
    "                           rates=[1, 1, 1, 1],\n",
    "                           padding='SAME')\n",
    "    \n",
    "    p1 = linear(p1)\n",
    "    p2 = linear(p2)\n",
    "    #print(p1, p2)\n",
    "          \n",
    "    for x in y[0]:\n",
    "        for i,j in enumerate(x):\n",
    "            for k,l in enumerate(x):\n",
    "                #print(i,k)\n",
    "                \n",
    "                p3 = np.asarray([i,k])\n",
    "                #print(p1, p2, p3)\n",
    "\n",
    "                dis = np.abs(np.cross(p2-p1, p1-p3)) / np.linalg.norm(p2-p1)\n",
    "                #print(dis)\n",
    "                \n",
    "                if(test != True):\n",
    "                    if (dis <= threshold):\n",
    "                        gTruth[i][k] = 1\n",
    "                    else:\n",
    "                        gTruth[i][k] = 0\n",
    "                else:\n",
    "                    if (dis <= threshold):\n",
    "                        gTruth[i][k] = 0\n",
    "                    else:\n",
    "                        gTruth[i][k] = 255\n",
    "    #print(gTruth.shape)\n",
    "    #plt.imshow(gTruth)\n",
    "    return gTruth\n",
    "    \n",
    "    \n",
    "#gtDistance2(178, False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def test_sbs(index, method):\n",
    "    image, class_id, x, y = getInfo(index)\n",
    "    pimg = method(index, False)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(pimg)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(image)\n",
    "    plt.subplot(121)\n",
    "    plt.plot(pimg)\n",
    "'''  \n",
    "#test_sbs(133, gtDistance2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel gTruth and Line gTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def linear(coord):\n",
    "    n_a = []\n",
    "    \n",
    "    for i in coord:\n",
    "        OldValue = i\n",
    "        OldMax = image_width-1\n",
    "        OldMin = 0\n",
    "        NewMax = gridcell-1\n",
    "        NewMin = 0\n",
    "        OldRange = (OldMax - OldMin)  \n",
    "        NewRange = (NewMax - NewMin)  \n",
    "        x = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
    "        n_a.append(x)\n",
    "    \n",
    "    return np.asarray(n_a)\n",
    "\n",
    "def midPoint(p12):\n",
    "    x1, x2, y1, y2 = p12\n",
    "    \n",
    "    x = (x1 + x2)/2\n",
    "    y = (y1 + y2)/2\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "def gtruther(index):\n",
    "\n",
    "    image, class_id, coords = getInfo(index)\n",
    "    \n",
    "    #truther shapes\n",
    "    pxTruth = np.zeros((gridcell,gridcell,1))\n",
    "    liTruth = np.zeros((gridcell,gridcell,4))\n",
    "    mps = []\n",
    "    \n",
    "    if (class_id == 1):\n",
    "        for i in coords:\n",
    "            x1, y1, x2, y2 = i\n",
    "            \n",
    "            #p12 = i\n",
    "            #mapping\n",
    "            #print(\"old coords: \", i)\n",
    "            p12 = linear(i)\n",
    "            #print(\"new coords: \", p12)\n",
    "\n",
    "            #find mp\n",
    "            mp = midPoint(p12)\n",
    "            mp = np.around(mp)\n",
    "            #print(mp)\n",
    "            #mp coords\n",
    "            y, x = mp.astype(int)\n",
    "\n",
    "            #line coords\n",
    "            x1, x2, y1, y2 = p12\n",
    "\n",
    "            #allot line gt coords of mp coords to liTruth shape\n",
    "            liTruth[x][y] = i\n",
    "            pxTruth[x][y] = [class_id]\n",
    "            mps.append([x,y])\n",
    "            \n",
    "\n",
    "    return image, liTruth, pxTruth, class_id, mps\n",
    "    \n",
    "#gtruther(\"li_200\")\n",
    "\n",
    "def test_sbs(index):\n",
    "    image, class_id, coords = getInfo(index)\n",
    "    pimg, liTruth, pxTruth, class_id, mps = gtruther(index)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    #plt.tight_layout(pad=0)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(pxTruth)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(liTruth)\n",
    "    \n",
    "test_sbs(\"li_222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_calc(pxTruth):\n",
    "    \n",
    "    n_s = []\n",
    "    \n",
    "    for i,j in enumerate(pxTruth):\n",
    "        for k,l in enumerate(pxTruth):\n",
    "            n_s.append(0 if pxTruth[i][k] == 0 else 1.5)\n",
    "            \n",
    "    return n_s\n",
    "    '''\n",
    "    for i in mps:\n",
    "        y, x = i\n",
    "        sample_weight[y][x] = 1.5\n",
    "    return sample_weight\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check line 13 later - random???\"\n",
    "def regression_weight_map(cls_target):\n",
    "    '''Creates a weight map for the regression target.\n",
    "       The weight map is 1.0 where the classification target is not zero.\n",
    "       Shape=(B,H,W)  (no channel dimension as required by the loss functions)'''\n",
    "    return (cls_target[...,0] > 0).astype('float32')\n",
    "\n",
    "batch_size = len(total_files)\n",
    "def data_generator(batch_size=batch_size):\n",
    "    while True:\n",
    "        x_batch = np.zeros((batch_size, image_height, image_width, 3))\n",
    "        y_batch = np.zeros((batch_size, gridcell, gridcell, 1))\n",
    "        bline_batch = np.zeros((batch_size, gridcell, gridcell, 4))\n",
    "        sample_weight = np.zeros((batch_size, 100))\n",
    "        \n",
    "        #print(sample_weight.shape)\n",
    "        #print(bline_batch)\n",
    "\n",
    "        for i,j in enumerate(total_files[0:batch_size]):\n",
    "            #j = j[0:-4]\n",
    "\n",
    "            image, liTruth, pxTruth, class_id, mps = gtruther(randlGen())\n",
    "            \n",
    "            x_batch[i] = image / 255.\n",
    "            y_batch[i] = pxTruth\n",
    "            bline_batch[i] = liTruth\n",
    "            \n",
    "            #sample_weight[i] = weight_calc(pxTruth)\n",
    "            #sample_weight.append(0 if class_id == 0 else 1.5)\n",
    "            #print(({'image': x_batch}, {'class_out': y_batch, 'line_out': bline_batch}))\n",
    "        sample_weight = regression_weight_map(y_batch)\n",
    "        #print(sample_weight.shape)\n",
    "        yield ({'image': x_batch}, {'class_out': y_batch, 'line_out': bline_batch}, {'class_out': sample_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(class_id, pred_coords):\n",
    "\n",
    "    #for label\n",
    "    count = 0\n",
    "    pos = []\n",
    "    coords = []\n",
    "\n",
    "    #gT label\n",
    "    for i,j in enumerate(class_id):\n",
    "        for k,l in enumerate(class_id):\n",
    "            if(class_id[i][k] == 1):\n",
    "                pos.append([i,k])\n",
    "                count = count + 1\n",
    "\n",
    "    for i,j in enumerate(pred_coords):\n",
    "        for k,l in enumerate(pred_coords):\n",
    "            if (all(i != 0 for i in pred_coords[i][k])):\n",
    "                coords.append(pred_coords[i][k])\n",
    "\n",
    "    #print(count, coords)\n",
    "    return count, coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def testerxo():\n",
    "    index = 95\n",
    "    example, label, sample_weight = next(data_generator(100))\n",
    "    image = example['image'][index]\n",
    "    class_id = label['class_out'][index]\n",
    "    pred_coords = label['line_out'][index]\n",
    "\n",
    "    count, coords = extractor(class_id, pred_coords)\n",
    "\n",
    "    image = plot_line(image, coords, norm=True)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.title('line')\n",
    "    plt.show()\n",
    "\n",
    "    '''\n",
    "    x = [pred_coords[0], pred_coords[1]]\n",
    "    y = [pred_coords[2], pred_coords[3]]\n",
    "\n",
    "    image = plot_line(image, pred_coords=[x, y], norm=True)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.title('line')\n",
    "    plt.show()\n",
    "    '''\n",
    "testerxo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef model2():\\n    \\n    backbone             = keras.applications.MobileNet(include_top=False, pooling='avg')\\n    classification_layer = keras.layers.Dense(1, activation='softmax', name='class_out')\\n    regression_layer     = keras.layers.Dense(4, name='box_out')\\n\\n    x = x0   = keras.Input(shape=(None,None,3), name='image')\\n    x        = backbone(x)\\n    x1        = classification_layer(x)\\n    x2        = regression_layer(x)\\n    model    = keras.Model(inputs=x0, outputs=[x1, x2])\\n    \\n    return model\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def model2():\n",
    "    \n",
    "    backbone             = keras.applications.MobileNet(include_top=False, pooling='avg')\n",
    "    classification_layer = keras.layers.Dense(1, activation='softmax', name='class_out')\n",
    "    regression_layer     = keras.layers.Dense(4, name='box_out')\n",
    "\n",
    "    x = x0   = keras.Input(shape=(None,None,3), name='image')\n",
    "    x        = backbone(x)\n",
    "    x1        = classification_layer(x)\n",
    "    x2        = regression_layer(x)\n",
    "    model    = keras.Model(inputs=x0, outputs=[x1, x2])\n",
    "    \n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model2()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, 400, 400, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 398, 398, 16) 448         image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 398, 398, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 199, 199, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 197, 197, 32) 4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 197, 197, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 98, 98, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 96, 96, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 48, 48, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 46, 46, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 46, 46, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 23, 23, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 21, 21, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 21, 21, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "class_out (Conv2D)              (None, 10, 10, 1)    257         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "line_out (Conv2D)               (None, 10, 10, 4)    1028        max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 395,877\n",
      "Trainable params: 394,885\n",
      "Non-trainable params: 992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def modelTester():\n",
    "    input_ = Input(shape=(image_height, image_width, 3), name='image')\n",
    "\n",
    "    x = input_\n",
    "\n",
    "    for i in range(0, 5):\n",
    "      n_filters = 2**(4 + i)\n",
    "      x = Conv2D(n_filters, 3, activation='relu')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = MaxPool2D(2)(x)\n",
    "    \n",
    "    x1 = Conv2D(1, (1,1), name=\"class_out\")(x)\n",
    "    x2 = Conv2D(4, (1,1), name=\"line_out\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(input_, [x1,x2])\n",
    "    model.summary()\n",
    "    return model\n",
    "    \n",
    "model = modelTester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    h = w = 600\n",
    "    \n",
    "    backbone             = keras.applications.MobileNet(input_shape=(h,w,3), include_top=False)\n",
    "    \n",
    "    x = x0   = keras.Input(shape=(h,w,3), name='image')\n",
    "    x        = backbone(x)\n",
    "    \n",
    "    x1 = Conv2D(1, (1,1), name=\"class_out\")(x)\n",
    "    x2 = Conv2D(4, (1,1), name=\"line_out\")(x)\n",
    "    #x = Conv2D(2048, (7, 7), strides = (1, 1))(x)\n",
    "    model    = keras.Model(inputs=x0, outputs=[x1,x2])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#model = model1()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#_metrics = ['tf.keras.metrics.RootMeanSquaredError()', '']\n",
    "model.compile(\n",
    "    loss={\n",
    "        'class_out': 'binary_crossentropy',\n",
    "        'line_out': 'mse'\n",
    "    },\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics={\n",
    "        'class_out': 'accuracy',\n",
    "        'line_out': [tf.keras.metrics.MeanAbsoluteError()]\n",
    "    },\n",
    "    sample_weight_mode=\"temporal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(model, test_datagen):\n",
    "\n",
    "    example, label, sample_weight = next(test_datagen)\n",
    "\n",
    "    image = example['image']\n",
    "    class_id = label['class_out']\n",
    "\n",
    "    #gtruth lines\n",
    "    coords = label['line_out']\n",
    "    gtcount, gtcoords = extractor(class_id[0], coords[0])\n",
    "\n",
    "    #predicted lines\n",
    "    pred_class, pred_line = model.predict(image)\n",
    "    pred_count, pred_coords = extractor(pred_class[0], pred_line[0])\n",
    "\n",
    "    #class_id\n",
    "    gt = 0 if gtcount == 0 else 1\n",
    "    pred_class_name = 0 if pred_count == 0 else 1\n",
    "\n",
    "    image = plot_line(image[0], pred_coords)\n",
    "\n",
    "    color = 'green' if gt == pred_class_name else 'red'\n",
    "\n",
    "    plt.imshow(np.flipud(image))\n",
    "\n",
    "    plt.xlabel(f'Pred: {pred_class_name}', color=color)\n",
    "    plt.ylabel(f'GT: {gt}', color=color)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    '''\n",
    "    example, label = next(test_datagen)\n",
    "    x = example['image']\n",
    "    y = label['class_out']\n",
    "    box = label['line_out'][0]   \n",
    "\n",
    "    pred_y, pred_box = model.predict(x)\n",
    "\n",
    "    pred_coords = pred_box[0]\n",
    "    xc = [pred_coords[0], pred_coords[1]]\n",
    "    yc = [pred_coords[2], pred_coords[3]]\n",
    "\n",
    "    #print(xc, yc)\n",
    "\n",
    "    pred_class = np.argmax(pred_y[0])\n",
    "    image = x[0]\n",
    "\n",
    "    gt = \"line\"\n",
    "    pred_class_name = \"line\"\n",
    "\n",
    "    box = [[box[0], box[1]], [box[2], box[3]]]\n",
    "\n",
    "    image = plot_line(image, pred_coords=[xc, yc], norm=True)\n",
    "    color = 'green' if gt == pred_class_name else 'red'\n",
    "\n",
    "    plt.imshow(image)\n",
    "    #plt.show()\n",
    "    plt.xlabel(f'Pred: {pred_class_name}', color=color)\n",
    "    plt.ylabel(f'GT: {gt}', color=color)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(model):\n",
    "    test_datagen = data_generator(1)\n",
    "\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        plt.subplot(1, 6, i + 1)\n",
    "        test_model(model, test_datagen)\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv2d/Relu (defined at <ipython-input-16-f24eecec10e3>:13) ]] [Op:__inference_predict_function_574]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5bfdcc797401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-7da902b440fa>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_datagen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-f24eecec10e3>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_datagen)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#predicted lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpred_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mpred_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m               *args, **kwds)\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[1;32m    895\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv2d/Relu (defined at <ipython-input-16-f24eecec10e3>:13) ]] [Op:__inference_predict_function_574]\n\nFunction call stack:\npredict_function\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowTestImages(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    test(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    def lr_schedule(epoch, lr):\n",
    "      if (epoch + 1) % 5 == 0:\n",
    "        lr *= 0.2\n",
    "      return max(lr, 3e-7)\n",
    "\n",
    "\n",
    "    _ = model.fit(\n",
    "        data_generator(batch_size=100),\n",
    "        use_multiprocessing=True,\n",
    "        workers=24,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=500,\n",
    "        callbacks=[\n",
    "                   ShowTestImages(),\n",
    "                   #tf.keras.callbacks.EarlyStopping(monitor='line_out_mean_absolute_error', patience=3, mode='max'),\n",
    "                   tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "        ]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Object Localization with TensorFlow - Starter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
