{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from numpy.random import rand, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import bezier\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv1D, Conv2D, Conv3D, MaxPool2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Activation\n",
    "\n",
    "print('Using TensorFlow version', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 648x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 9))\n",
    "image_width = image_height = 600\n",
    "\n",
    "image_root = './images/multi_lines/train/'\n",
    "image_labels = ['line']\n",
    "\n",
    "total_files = fnmatch.filter(os.listdir(image_root), '*.png')\n",
    "#print(total_files)\n",
    "\n",
    "df=pd.read_csv('./images/multi_lines/train.csv', sep=',',header=0)\n",
    "\n",
    "def image_read(fn):\n",
    "    link = os.path.join(image_root, fn)\n",
    "    image = Image.open(link).convert('RGB')\n",
    "    im = np.asarray(image)\n",
    "    #print(im.shape)\n",
    "    return im\n",
    "    \n",
    "def generate_bezier(x, y):\n",
    "    nr = np.asarray(x, y)\n",
    "    curve = bezier.Curve(nr, degree=1)\n",
    "    \n",
    "    return curve\n",
    "\n",
    "def gen_plots():\n",
    "    for i in range(9):\n",
    "        rand_idx = randint(0, len(total_files))\n",
    "        image, class_id, x, y = getInfo(rand_idx)\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        \n",
    "        l1 = ax.imshow(image, extent=[0, image_height, 0, image_width])\n",
    "        l1.set_label(\"\")\n",
    "        \n",
    "        # Create bezier curve or plot a line\n",
    "        '''\n",
    "        curve = generate_bezier(x, y)\n",
    "        g_truth = curve.plot(num_pts=256, color=\"r\", ax=ax)\n",
    "        g_truth.lines[-1].set_label('prediction var 1')\n",
    "        g_truth.lines[-1].set_linestyle('dotted')\n",
    "        g_truth.lines[-1].set_marker('+')\n",
    "        g_truth.lines[-1].set_markersize(2)\n",
    "        '''\n",
    "        \n",
    "        ax.plot(x, y, 'r+', linestyle='dotted', label='prediction')\n",
    "        \n",
    "        lines, labels = ax.get_legend_handles_labels()\n",
    "        plt.legend( lines, labels, loc = 'best', bbox_to_anchor = (0,-0.1,1,1),\n",
    "                    bbox_transform = plt.gcf().transFigure )\n",
    "        \n",
    "        plt.xlabel(image_labels[0])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "#gen_plots()\n",
    "\n",
    "\n",
    "def getInfo(fn):\n",
    "    #print(fn)\n",
    "    image = image_read(fn+\".png\")\n",
    "    \n",
    "    rows = np.where(df.filename==fn)\n",
    "    \n",
    "    class_id = df[\"class\"][rows[0][0]]\n",
    "    coords = []\n",
    "    \n",
    "    for i in rows[0]:\n",
    "        c_id = []\n",
    "        c_coord = []\n",
    "        \n",
    "        c_coord.append(df.xmin[i])\n",
    "        c_coord.append(df.xmax[i])\n",
    "        c_coord.append(df.ymin[i])\n",
    "        c_coord.append(df.ymax[i])\n",
    "        \n",
    "        coords.append(c_coord)\n",
    "        c_id = []\n",
    "    \n",
    "    return image, class_id, coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1793,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tester():\n",
    "    rand_idx = randint(0, len(total_files))\n",
    "    image, class_id, x, y = getInfo(rand_idx)\n",
    "    return image\n",
    "\n",
    "def plot_line(image, pred_coords, norm=False):\n",
    "    figo = Figure(figsize=(2, 2))\n",
    "\n",
    "    canvas = FigureCanvasAgg(figo)\n",
    "\n",
    "    # plot\n",
    "    ax_r = figo.add_subplot()\n",
    "    if norm:\n",
    "        image *= 255.\n",
    "        image = image.astype(np.uint8)\n",
    "    ax_r.imshow(image, extent=[0,image_height,0,image_width])\n",
    "    \n",
    "    for i in pred_coords:\n",
    "        xmin, xmax, ymin, ymax = i\n",
    "        ax_r.plot([xmin, xmax], [ymin, ymax], 'r+', linestyle='dotted', label='prediction')\n",
    "    \n",
    "    '''\n",
    "    if len(pred_coords) == 2:\n",
    "        x, y = pred_coords\n",
    "        #print(x, y)\n",
    "        xmin = x[0]\n",
    "        xmax = x[1]\n",
    "        ymin = y[0]\n",
    "        ymax = y[1]\n",
    "        ax_r.plot([xmin, xmax], [ymin, ymax], 'r+', linestyle='dotted', label='prediction')\n",
    "    '''\n",
    "    ax_r.set_axis_off()\n",
    "\n",
    "    canvas.draw()\n",
    "\n",
    "    buf = canvas.buffer_rgba()\n",
    "    # ... convert to a NumPy array ...\n",
    "    X = np.asarray(buf)\n",
    "    # ... and pass it to PIL.\n",
    "    im = Image.fromarray(X)\n",
    "\n",
    "    return im\n",
    "\n",
    "def randlGen():\n",
    "    rElem = np.random.choice(total_files)\n",
    "    rElem = rElem[0:-4]\n",
    "    return rElem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#rand_idx = randint(0, len(total_files))\n",
    "\n",
    "image, class_id, pred_coords = getInfo(randlGen())\n",
    "\n",
    "image = plot_line(image, pred_coords)\n",
    "plt.imshow(np.flipud(image))\n",
    "plt.title(\"line\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truth pixels with testing (DISBANDED!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef test_sbs(index, method):\\n    image, class_id, x, y = getInfo(index)\\n    pimg = method(index, False)\\n    \\n    plt.subplot(1, 2, 1)\\n    plt.imshow(image)\\n    plt.subplot(1, 2, 2)\\n    plt.imshow(pimg)\\n    \\n    plt.subplot(121)\\n    plt.plot(image)\\n    plt.subplot(121)\\n    plt.plot(pimg)\\n'"
      ]
     },
     "execution_count": 1812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def gtDistance1(index, test):\n",
    "    \n",
    "    threshold = 0.01\n",
    "    image, class_id, p1, p2 = getInfo(index)\n",
    "\n",
    "    gTruth = np.zeros((h,w,1))\n",
    "    \n",
    "    p1 = np.asarray([x / image_height for x in p1])\n",
    "    p2 = np.asarray([x / image_width for x in p2])\n",
    "    \n",
    "    #print(p1)\n",
    "    \n",
    "    for i,j in enumerate(image):\n",
    "        for k,l in enumerate(image):\n",
    "            x1 = i/h \n",
    "            x2 = k/w\n",
    "            p3 = np.asarray([x1,x2])\n",
    "            \n",
    "            dis = np.abs(np.cross(p2-p1, p1-p3)) / np.linalg.norm(p2-p1)\n",
    "            #print(dis)\n",
    "            if(test != True):\n",
    "                if (dis <= threshold):\n",
    "                    gTruth[i][k] = 1\n",
    "                else:\n",
    "                    gTruth[i][k] = 0\n",
    "            else:\n",
    "                if (dis <= threshold):\n",
    "                    gTruth[i][k] = 0\n",
    "                else:\n",
    "                    gTruth[i][k] = 255\n",
    "    #print(gTruth)\n",
    "    return gTruth\n",
    "\n",
    "\n",
    "def gtNaive(index):\n",
    "    image, class_id, x, y = getInfo(index)\n",
    "    # Naive non-generalized method\n",
    "    \n",
    "    gTruth = np.zeros((h,w,1))\n",
    "    #x[0][0] = [2]\n",
    "    \n",
    "    for i,j in enumerate(image):\n",
    "        for k,l in enumerate(image):\n",
    "            if (np.all(image[i][k] == 255)):\n",
    "                gTruth[i][k] = 0\n",
    "            else:\n",
    "                gTruth[i][k] = 255\n",
    "    return [image,gTruth]\n",
    "\n",
    "#gtNaive(1)\n",
    "\n",
    "#test_sbs(311, gtDistance2)\n",
    "\n",
    "'''\n",
    "x, y = gtNaive(103)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(y)\n",
    "'''\n",
    "'''\n",
    "def linear(coord):\n",
    "    \n",
    "    n_a = []\n",
    "    \n",
    "    for i in coord:\n",
    "        OldValue = i\n",
    "        OldMax = 143\n",
    "        OldMin = 0\n",
    "        NewMax = 17\n",
    "        NewMin = 0\n",
    "        OldRange = (OldMax - OldMin)  \n",
    "        NewRange = (NewMax - NewMin)  \n",
    "        x = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
    "        n_a.append(x)\n",
    "    \n",
    "    return np.asarray(n_a)\n",
    "'''\n",
    "def gtDistance2(index, test):\n",
    "    \n",
    "    threshold = 1\n",
    "    image_orig, class_id, p1, p2 = getInfo(index)\n",
    "    image = image_orig.reshape((1,image_height,image_width,3))\n",
    "    \n",
    "    gTruth = np.zeros((18,18,1))\n",
    "    \n",
    "    y = tf.image.extract_patches(images=image,\n",
    "                           sizes=[1, 8, 8, 1],\n",
    "                           strides=[1, 8, 8, 1],\n",
    "                           rates=[1, 1, 1, 1],\n",
    "                           padding='SAME')\n",
    "    \n",
    "    p1 = linear(p1)\n",
    "    p2 = linear(p2)\n",
    "    #print(p1, p2)\n",
    "          \n",
    "    for x in y[0]:\n",
    "        for i,j in enumerate(x):\n",
    "            for k,l in enumerate(x):\n",
    "                #print(i,k)\n",
    "                \n",
    "                p3 = np.asarray([i,k])\n",
    "                #print(p1, p2, p3)\n",
    "\n",
    "                dis = np.abs(np.cross(p2-p1, p1-p3)) / np.linalg.norm(p2-p1)\n",
    "                #print(dis)\n",
    "                \n",
    "                if(test != True):\n",
    "                    if (dis <= threshold):\n",
    "                        gTruth[i][k] = 1\n",
    "                    else:\n",
    "                        gTruth[i][k] = 0\n",
    "                else:\n",
    "                    if (dis <= threshold):\n",
    "                        gTruth[i][k] = 0\n",
    "                    else:\n",
    "                        gTruth[i][k] = 255\n",
    "    #print(gTruth.shape)\n",
    "    #plt.imshow(gTruth)\n",
    "    return gTruth\n",
    "    \n",
    "    \n",
    "#gtDistance2(178, False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def test_sbs(index, method):\n",
    "    image, class_id, x, y = getInfo(index)\n",
    "    pimg = method(index, False)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(pimg)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(image)\n",
    "    plt.subplot(121)\n",
    "    plt.plot(pimg)\n",
    "'''  \n",
    "#test_sbs(133, gtDistance2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel gTruth and Line gTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1825,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(coord):\n",
    "    n_a = []\n",
    "    \n",
    "    for i in coord:\n",
    "        OldValue = i\n",
    "        OldMax = image_width-1\n",
    "        OldMin = 0\n",
    "        NewMax = 17\n",
    "        NewMin = 0\n",
    "        OldRange = (OldMax - OldMin)  \n",
    "        NewRange = (NewMax - NewMin)  \n",
    "        x = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
    "        n_a.append(x)\n",
    "    \n",
    "    return np.asarray(n_a)\n",
    "\n",
    "def midPoint(p12):\n",
    "    x1, x2, y1, y2 = p12\n",
    "    \n",
    "    x = (x1 + x2)/2\n",
    "    y = (y1 + y2)/2\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "def gtruther(index):\n",
    "\n",
    "    image, class_id, coords = getInfo(index)\n",
    "    \n",
    "    #truther shapes\n",
    "    pxTruth = np.zeros((18,18,1))\n",
    "    liTruth = np.zeros((18,18,4))\n",
    "    \n",
    "    if (class_id == 1):\n",
    "        for i in coords:\n",
    "            x1, x2, y1, y2 = i\n",
    "            \n",
    "            #p12 = i\n",
    "            #mapping\n",
    "            #print(\"old coords: \", i)\n",
    "            p12 = linear(i)\n",
    "            #print(\"new coords: \", p12)\n",
    "\n",
    "            #find mp\n",
    "            mp = midPoint(p12)\n",
    "            mp = np.around(mp)\n",
    "            #print(mp)\n",
    "            #mp coords\n",
    "            x, y = mp.astype(int)\n",
    "\n",
    "            #line coords\n",
    "            x1, x2, y1, y2 = p12\n",
    "\n",
    "            #allot line gt coords of mp coords to liTruth shape\n",
    "            liTruth[x][y] = i\n",
    "            pxTruth[y][x] = [class_id]\n",
    "            \n",
    "\n",
    "    return image, liTruth, pxTruth\n",
    "    \n",
    "#gtruther(\"li_200\")\n",
    "\n",
    "def test_sbs(index):\n",
    "    image, class_id, coords = getInfo(index)\n",
    "    pimg = gtruther(index)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    #plt.tight_layout(pad=0)\n",
    "    plt.imshow(np.flipud(image))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(pimg)\n",
    "    \n",
    "#test_sbs(\"li_401\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check line 13 later - random???\"\n",
    "\n",
    "batch_size = len(total_files)\n",
    "def data_generator(batch_size=batch_size):\n",
    "    while True:\n",
    "        x_batch = np.zeros((batch_size, image_height, image_width, 3))\n",
    "        y_batch = np.zeros((batch_size, 18, 18, 1))\n",
    "        bline_batch = np.zeros((batch_size, 18, 18, 4))\n",
    "        #print(bline_batch)\n",
    "        \n",
    "        for i,j in enumerate(total_files[0:batch_size]):\n",
    "            #j = j[0:-4]\n",
    "            \n",
    "            image, liTruth, pxTruth = gtruther(randlGen())\n",
    "            \n",
    "            x_batch[i] = image / 255.\n",
    "            y_batch[i] = pxTruth\n",
    "            bline_batch[i] = liTruth\n",
    "\n",
    "            #print(({'image': x_batch}, {'class_out': y_batch, 'line_out': bline_batch}))\n",
    "            \n",
    "        yield ({'image': x_batch}, {'class_out': y_batch, 'line_out': bline_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1801,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(class_id, pred_coords):\n",
    "    \n",
    "    #for label\n",
    "    count = 0\n",
    "    pos = []\n",
    "    coords = []\n",
    "    \n",
    "    #gT label\n",
    "    for i,j in enumerate(class_id):\n",
    "        for k,l in enumerate(class_id):\n",
    "            if(class_id[i][k] == 1):\n",
    "                pos.append([i,k])\n",
    "                count = count + 1\n",
    "    \n",
    "    for i,j in enumerate(pred_coords):\n",
    "        for k,l in enumerate(pred_coords):\n",
    "            if (all(i != 0 for i in pred_coords[i][k])):\n",
    "                coords.append(pred_coords[i][k])\n",
    "    \n",
    "    #print(count, coords)\n",
    "    return count, coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1802,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testerxo():\n",
    "    index = 94\n",
    "    example, label = next(data_generator(100))\n",
    "    print(example)\n",
    "    image = example['image'][index]\n",
    "    class_id = label['class_out'][index]\n",
    "    pred_coords = label['line_out'][index]\n",
    "\n",
    "    count, coords = extractor(class_id, pred_coords)\n",
    "\n",
    "    image = plot_line(image, coords, norm=True)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.title('line')\n",
    "    plt.show()\n",
    "\n",
    "    '''\n",
    "    x = [pred_coords[0], pred_coords[1]]\n",
    "    y = [pred_coords[2], pred_coords[3]]\n",
    "\n",
    "    image = plot_line(image, pred_coords=[x, y], norm=True)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.title('line')\n",
    "    plt.show()\n",
    "    '''\n",
    "#testerxo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1784,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def model2():\n",
    "    \n",
    "    backbone             = keras.applications.MobileNet(include_top=False, pooling='avg')\n",
    "    classification_layer = keras.layers.Dense(1, activation='softmax', name='class_out')\n",
    "    regression_layer     = keras.layers.Dense(4, name='box_out')\n",
    "\n",
    "    x = x0   = keras.Input(shape=(None,None,3), name='image')\n",
    "    x        = backbone(x)\n",
    "    x1        = classification_layer(x)\n",
    "    x2        = regression_layer(x)\n",
    "    model    = keras.Model(inputs=x0, outputs=[x1, x2])\n",
    "    \n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mobilenet_1.00_224 (Functional) (None, 1024)         3228864     image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "class_out (Dense)               (None, 1)            1025        mobilenet_1.00_224[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "box_out (Dense)                 (None, 4)            4100        mobilenet_1.00_224[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 3,233,989\n",
      "Trainable params: 3,212,101\n",
      "Non-trainable params: 21,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = model2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_123\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, 600, 600, 3)]     0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def modelTester():\n",
    "    input_ = Input(shape=(image_height, image_width, 3), name='image')\n",
    "\n",
    "    x = input_\n",
    "\n",
    "    for i in range(0, ):\n",
    "      n_filters = 2**(4 + i)\n",
    "      x = Conv2D(n_filters, 1, activation='relu')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = MaxPool2D(2)(x)\n",
    "    '''\n",
    "    x1 = Conv2D(1, (3,3), name=\"class_out\")(x)\n",
    "    x2 = Conv2D(4, (3,3), name=\"line_out\")(x)\n",
    "    '''\n",
    "    model = tf.keras.models.Model(input_, [x])\n",
    "    model.summary()\n",
    "    \n",
    "#modelTester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model_125\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, 600, 600, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mobilenet_1.00_224 (Functional) (None, 18, 18, 1024) 3228864     image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "class_out (Conv2D)              (None, 18, 18, 1)    1025        mobilenet_1.00_224[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "line_out (Conv2D)               (None, 18, 18, 4)    4100        mobilenet_1.00_224[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 3,233,989\n",
      "Trainable params: 3,212,101\n",
      "Non-trainable params: 21,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model1():\n",
    "    h = w = 600\n",
    "    \n",
    "    backbone             = keras.applications.MobileNet(input_shape=(h,w,3), include_top=False)\n",
    "    \n",
    "    x = x0   = keras.Input(shape=(h,w,3), name='image')\n",
    "    x        = backbone(x)\n",
    "    \n",
    "    x1 = Conv2D(1, (1,1), name=\"class_out\")(x)\n",
    "    x2 = Conv2D(4, (1,1), name=\"line_out\")(x)\n",
    "    #x = Conv2D(2048, (7, 7), strides = (1, 1))(x)\n",
    "    model    = keras.Model(inputs=x0, outputs=[x1,x2])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1804,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_metrics = ['tf.keras.metrics.RootMeanSquaredError()', '']\n",
    "model.compile(\n",
    "    loss={\n",
    "        'class_out': 'binary_crossentropy',\n",
    "        'line_out': 'mse'\n",
    "    },\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics={\n",
    "        'class_out': 'accuracy',\n",
    "        'line_out': [tf.keras.metrics.MeanAbsoluteError()]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1816,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line2(image, pred_coords, norm=False):\n",
    "    figo = Figure(figsize=(2, 2))\n",
    "\n",
    "    canvas = FigureCanvasAgg(figo)\n",
    "\n",
    "    # plot\n",
    "    ax_r = figo.add_subplot()\n",
    "    if norm:\n",
    "        image *= 255.\n",
    "        image = image.astype(np.uint8)\n",
    "    ax_r.imshow(image, extent=[0,image_height,0,image_width])\n",
    "    \n",
    "    for i in pred_coords:\n",
    "        xmin, xmax, ymin, ymax = i\n",
    "        ax_r.plot([xmin, xmax], [ymin, ymax], 'r+', linestyle='dotted', label='prediction')\n",
    "    \n",
    "    ax_r.set_axis_off()\n",
    "\n",
    "    canvas.draw()\n",
    "\n",
    "    buf = canvas.buffer_rgba()\n",
    "    # ... convert to a NumPy array ...\n",
    "    X = np.asarray(buf)\n",
    "    # ... and pass it to PIL.\n",
    "    im = Image.fromarray(X)\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1817,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_datagen):\n",
    "    \n",
    "    example, label = next(test_datagen)\n",
    "    \n",
    "    image = example['image']\n",
    "    class_id = label['class_out']\n",
    "    \n",
    "    #gtruth lines\n",
    "    coords = label['line_out']\n",
    "    gtcount, gtcoords = extractor(class_id[0], coords[0])\n",
    "    \n",
    "    #predicted lines\n",
    "    pred_class, pred_line = model.predict(image)\n",
    "    pred_count, pred_coords = extractor(pred_class[0], pred_line[0])\n",
    "\n",
    "    #class_id\n",
    "    gt = 0 if gtcount == 0 else 1\n",
    "    pred_class_name = 0 if pred_count == 0 else 1\n",
    "    \n",
    "    image = plot_line2(image[0], pred_coords, norm=True)\n",
    "\n",
    "    color = 'green' if gt == pred_class_name else 'red'\n",
    "    \n",
    "    plt.imshow(np.flipud(image))\n",
    "    \n",
    "    plt.xlabel(f'Pred: {pred_class_name}', color=color)\n",
    "    plt.ylabel(f'GT: {gt}', color=color)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    '''\n",
    "    example, label = next(test_datagen)\n",
    "    x = example['image']\n",
    "    y = label['class_out']\n",
    "    box = label['line_out'][0]   \n",
    "\n",
    "    pred_y, pred_box = model.predict(x)\n",
    "\n",
    "    pred_coords = pred_box[0]\n",
    "    xc = [pred_coords[0], pred_coords[1]]\n",
    "    yc = [pred_coords[2], pred_coords[3]]\n",
    "\n",
    "    #print(xc, yc)\n",
    "\n",
    "    pred_class = np.argmax(pred_y[0])\n",
    "    image = x[0]\n",
    "\n",
    "    gt = \"line\"\n",
    "    pred_class_name = \"line\"\n",
    "\n",
    "    box = [[box[0], box[1]], [box[2], box[3]]]\n",
    "\n",
    "    image = plot_line(image, pred_coords=[xc, yc], norm=True)\n",
    "    color = 'green' if gt == pred_class_name else 'red'\n",
    "\n",
    "    plt.imshow(image)\n",
    "    #plt.show()\n",
    "    plt.xlabel(f'Pred: {pred_class_name}', color=color)\n",
    "    plt.ylabel(f'GT: {gt}', color=color)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1818,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    test_datagen = data_generator(1)\n",
    "    \n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        plt.subplot(1, 6, i + 1)\n",
    "        test_model(model, test_datagen)\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1822,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5kAAACbCAYAAADodl+wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ5UlEQVR4nO3da4yc12He8f+Z+87euVzeSYmSTEuyTd0qxxGaRL41ceTUbp02RYCkDVo3SW9ADDgf0sKb8YeiQD4VjtEGaFEnBdokqBHDqe0YCBLYjhvJsRUpsqRItkSR4kUkd7m73N3Z3dmdOf3w7pLL24pcvi9nZ+b/AwbkzKxmj40Hh+eZ815CjBFJkiRJktKQa/cAJEmSJEndw5IpSZIkSUqNJVOSJEmSlBpLpiRJkiQpNZZMSZIkSVJqCll86M6dO+Pdd9+dxUerA3zve9+bjDGOZ/k7zFhvM2PKmhlT1syYsmbGlLXNMpZJybz77rv57ne/m8VHqwOEEI5n/TvMWG8zY8qaGVPWzJiyZsaUtc0y5uGykiRJkqTUWDIlSZIkSamxZEqSJEmSUmPJlCRJkiSlxpIpSZIkSUqNJVOSJEmSlBpLpiRJkiQpNZZMSZIkSVJqLJmSJEmSpNRYMiVJkiRJqbFkSpIkSZJSY8mUJEmSJKXGkilJkiRJSo0lU5IkSZKUms4qmTG2ewTqdmZMWTNjypoZU9bMmLJmxjpe55TMVgs++EGYn2/3SNStVlfh/e93YlO2nnrKeUzZeuopWFho9yjUzZzHlCXXY12hc0rmF78Izz4LO3YYOmXjN38TvvGNdo9CvcB5TFnbt8+MKVvOY8qK67GuUGj3AN7W4iK88gr87u/C7Czk8/DcczA8DPfc0+7RqRusZ+y555Ln3/kOlMswNGTGlI71jAGcOJEcmeE8pjRdnbGFBTOmdDmPKWuux7rK9i6Zq6vw+c/Dpz99+bVmEx59NAnbl78M73pX+8anzre0BL/+6/Dbv335tfe9L/nzox+FP/7j9oxL3eWVV+CRR658zXlMabpRxu67L8nYAw+0Z1zqHs5jypLrsa6zvQ+XzeeTfxiLxWvfO3YMfuu37vyY1F1KJfjMZ+DcOfiFX0he++IX4Wtfg9/4jfaOTd3PeUxpCuHa1yYn4c///M6PRb3j+HH43OfaPQp1OtdjXWd772SGAB/5SHJy+ac+lexqhgDf/z7kcjA42O4RqtPlcjA+nvz90KHkzw9+MDn8R0rL0aPJt7TPPw+f+AScOuU8pnQdPZocagbwkz8J3/xmkrFiEXbtau/Y1B3W57Hjx5OMHT9+eR7z30zdLtdjXWd7l0xIQlcqwcc+Br//+zA9Dfffn7wupSmEZPdcSlsul5xX8vjjySFlp087jyld6xkDqFaT+cyMKU3rGTtyBN75zuS8TDOmLLge6wqdMzN8+MPJMdnr325IafvsZ6HRSE4wl7IQQpKvgwfbPRJ1s8HB5LCz6x0+q1TEGIkx0mz16NVVh4Y8B1PZcT3WFbb/TuZGX/hCu0egbhaCizJl7w//sN0jULf7gz9o9wi6VlIuYX55hZn6KgCHxqptHlUbOI9d3/otXWITwtpOnOuKW+d6rCt0VsmUJEm6w2KMtCLM1hucnVvmxNQC9UaT9x7e0e6haTuIMXk05mFxClpNGDnsocTqaZZMSZKk67hULhcbnJ5ZYrbeYHG1xX27B7lrR5V8zt2WnhYjxBYsTsPsm7A8B81VGNwNRkM9zpIpSZK0QYyRCMwvrfLauXnmG6sMlAscHh9g50CZYj5pEMFD+npTjMkhsbOn4cLr0FqBUj8M7oOhfVDsS37OfKiHWTIlSZLWxBi5uLjKS2dmmV1cYf9IH0d2DzJaLVHMB4tlL4sRmg04/ypMvgLlQRjaD9UxqO6AfCn5OTMiWTIlSZJijMwtrfCdYxc4Ob3II4dGuH/PEP3lPMV8znLZy2KElQU4+2JSMAf3wMH3QWUYSlUIOYuldBVLpiRJ6jkxXr79yGKjyQunZnnx9EUe3DfEzz62k0oxd+mcSwtmj7l0ldgIK4vw1vNw7mXYcRje+REoD0G+mPyM2ZCuy5IpSZJ6yvqtSJZWmrwxtcBLZy5ycLTKzz1+kGrp8k3gLZc9JkYgJhfvWZ6DM8/BhWOw6344+nPJeZcbmQ/phiyZkiSpJ8QYWW1F6surnJ9f5uUzFxmsFPnQA7sZ7itaKnvRxntbNupQvwDnX07+3P0uuPvvJudamg3pllgyJUlSV4sxstKMTC0sc3Z2ifNzyxTygR+9Zyc7BkrkLBC9Z71cNhtJoaxPwdzpZBdz/H4YOQi5guVS2iJLpiRJ6krrO5fn55Y5OV1npr5CpZjn4UMjjA2ULZe9KkZYqcPMm7A0k5x3mS/BrnfBwG7I5S2X0m2yZEqSpK4SY6QV4fzcMscm52lFqJbyPHRwhJ1rO5ceGttjYkwei9Mw9UNozEGhDypDMHYf9I16lVgpRZZMSZLUNVoxMjXf4PmTM+QCHBitMj5QZrCvQN5y2XtiTM63nD+XXCF2dRkG98LOI8n9LYvV5OfMhZQqS6YkSep4rRg5M7PEc29O04qRd+8fZudAmWqpQC54pdieEyPEFlw8BSf/Knm+e+1w2PJgcr4lWC6ljFgyJUlSx1m/z2UELsw3+MvXp5iuN/jRe8Y4uKOPUiFPwHLZMy7d9zRCq5kcEnv8L6FQhkM/AkMHkntbhlzyY+ZCypQlU5IkdYz1ctmMkYWlJi+enuXY1AIP7h3iww/uplzIXfpZC2YPWC+XrWZyAZ/zfwunn4X+cXjgKaiOX1kozYR0R1gyJUnStrdeLhurLeaXVzlxoc6xyQUO7+znE48eoFzIWSp7SYxAhNUlWJyF6TfgwuswuAeO/mMoDyeF0kxIbWHJlCRJHeHi4gpvTNU5NbPIrsEyP/XuPfQV85bLXrJ+ruXS7Nq9Lc8kfw7uhQc+mpxvieVSajdLpiRJ6gjzy6sU8oGfODJOtWS57CkxQnMF5s8mj0YdWivJhXz2P5ZcJdY8SNuGJVOSJHWEfSN97BvpAzzfsmfEtUNiZ07AxTOQy0GxH3YcTg6NzRUsl9I2ZMmUJEnbnqWyx8QIK3U4/wrMvgl9O2B4P/TvTA6JDXnLpbSNWTIlSZK0PcSYnG958q9g7i0YuxcO/giUh6BYwfMtpc5gyZQkSdKdd+neliQX81k4DyeegcULsP9ROPQEFErJIbFguZQ6iCVTkiRJd9alW5Asw/z55N6WK/XkIj6j90B+wxLVcil1HEumJEmSsre+c9lcgcZ8snN59vvQbMKBx2DkkBfykbqEJVOSJEnZWd+1bCwk97RcmISLp5JCeeC9MLQPQs5yKXURS6YkSZLSF+PahXxmYPYkLM5AcwkqI3D3j0HfSFIuJXUdS6YkSZLSs14u58/A5GvQXE7ubTmwC4YPQKmKV4mVutvWSmYIA8Q4n/JY1KNCLewG9gMROB0n4tk2D0m9wHnsxlYWIV+CXL7dI+lsZkxZ224ZixFaqzB9HM69lMwhI4egOgZ9o1CoJD9nudyWXI8pTVvdyXwJOJTmQNR7Qi08DPxXYBg4tfbygVALM8C/ihPx2TYNTb3BeexGjn8b9j4E/ePtHkmnM2PK2vbIWFy7SuzkK3DuZaiMJnNI3wiU+iHkLZbbmOsxZeHGJTOET93oHWAgk9Go13wB+OU4EZ/Z+GKohfcB/wN4qB2DUhdxHtuafDm5Cbol8+2ZMWVtO2Zs4/0tVxfh7EvJVWKH9sO9H0jOucwXk/ctl53gC7geU8o2O9v6PwKjwOBVj4G3+e+km9V/9YQGECfi00B/G8aj7uM8thVD+5IrP25cSOpGzJiytj0ztjwHb/wFPPe/YGkWHvw43PfB5MspC2ancT2m1G12uOyzwJeI8XvXvBPCv8hsROolXwu18BXg94A31147CPwi8CdtG5W6ifPYVlTHkkNmdTPMmLK2DTMW4dT3kgv4PPTzUOyzUHY212NK3WYl85eAqRu893cyGIt6TJyI/y7UwkeAj5GcaB6Ak8Dn40T8alsHp27hPLYVpWpyflVsQvAi5G/DjClr2zBjAe55cu2vlstO53pMWbjx6iHGVzZ5z6tNKRVxIn4N+Fq7x6Eu5Ty2NaGQ7EysLEHZ0wo3ZcaUte2YMYtl13E9prR5vogk6UohJIfMLl5o90gkSVIHsmRKkq41sCe5wqwkSdItsmRKkq41sAsWzrd7FJIkqQPdXMkM4aObPpduU6hdmamrn0u3zXns1lSGoDEPsdXukXQOM6asmTFlzPWY0nLjkhnCP9zw7PGr3r36uXTLQs2MKWPOY1uXK0IEmivtHsn2ZsaUNTOmjLkeUxY228n8D5f+FuPEFe9c/VzamksZixNXZurq59IWOY9tVQhQ7k92M7UZM6asmTFlzfWYUuc5mZKkK4UAuTz07YC6V5iVJEm3ZrO7bN9PCH9zndcDEInxaEZjUu+4P9RunLE4YcZ025zHtixAdQcsTMLYfd4X78bMmLJmxpQ112NK3WYl8xjwM3dqIOpJZkxZM2NbFXJQGoLp4+0eyXZnxpQ1M6asmTGlbrOS2SBGVxfKUiNOmDFlynnsdhTKyYV/YhPCZv9c9DQzpqyZMWXN9ZhSt9k5md++Y6NQrzJjypoZux25POQKsLLU7pFsZ2ZMWTNjypoZU+o2K5l/Sgj/+tKzEJ4hhNfXHv8o+6GpB/xpqF3OWKiFZ0ItvL72MGNKg/PYVoWQFMxSPyzPbfljYoybPrqAGVPWzJiy5npMqdusZH4a+PKG52WSe+U8CfxKhmNqiy5c+HSCnsqY2sKM3Y58EUoDsDQDNzkvbpxHm63IaivSWG2xuNLkwkKDV8/O8a0fTPLNV8/T6o6p1owpa2ZMWTNjSt1mJ9mUiPHNDc//ghingClC6M94XG0xOb/MYKVIueCdXe6QUpy4MmNxIslYqHVnxnTH9dw8lqpcAYoVWLp43bfXv5BrRWi2IivNFivNFs21Yjm7uMLUwjLTCyssN5uU8jl29Jc4MNrHzsEyue64YK0ZU9bMmLLmekyp26xkjl7xLMZ/s+HZeCajabMfnlugWspz9MBwu4fSK67IWJzo/ozpjuu5eSxVISS7matLRCKslcnl1dbao0ljtUWj2WJxuclCo8n88iqtVqRczDFUKXJgtMp79peolvLk11pl6K7boZgxZc2MKWuux5S6zbbsniGET17zagi/DHwnsxG1SQiB+/cM8vKZi6w0W+0eTq94JtSuzViodWfG1BY9NY+lKcbIagvmVgJnLy7zgzMzvHh6lhdPX+TlMxd57dw8x6fqnJ5ZZKa+QrGQ4/DOKk/cO8aHHtzFTxwZ59G7RrlrrJ+hviKFfI4QQrcVTDBjyp4ZU9Zcjyl1m+1k/hrwJUL4eeDZtdceIzlO++MZj6sthqtFhipFTlyoc+/4QDcuhrabXwO+FGq9kzHdcT03j6Vput7gjckGlXqTVn2BfN8glWKOkWqRwUqBaqlAKZ9jfars0TnTjClrZkxZcz2m1N24ZMZ4DniCED4AvGvt1a8Q45/diYG1Qy4EHj40wrd/OMnhnf3ke3PBdMfEiSRjoXZlxuJE92ZMd1gPzmNpGigXOLxnjL7KBYpjOQojw6zPij1aKK9lxpQ1M6aMuR5TFt7+7trJJNYzIds1WCYC5y4us3ekr93D6Qlrk1jPZExt0GPzWBpCCPSVCvQND8FSGZr19TfaO7Dtyowpa2ZMGXM9pjR5GdWr5HOBRw+N8PzJGW9lIkn5IoQcrC61eySSJKlDWDKvY99IH3OLq8wvr1o0JfW2kINcHlpNwPlQkiS9PUvmVUIIlAo5Do/384Oz8+0ejiS1X6EMsQnNlXaPRJIkdQBL5nXkQ+DgaB9vXVxiedXbmUjqYSFAaQCaq7C63O7RSJKkDmDJvIGBSpGhSoEzM4seMiupt5UGoLXqeZmSJOmmWDKvI4RApZhnfLDMqZlFVluWTEk9rFhNzslsNsAv3SR1gBgjzVaLsxeXWGx4jQ3pTrNk3kAuwI7+EhG4ML/s5CSpd+ULEPCcTEkdJUaYml/mm69O8vKZOZZXmq7npDvEkrmJkWqJajHPubllr6koqYcFyJfXdjI9T11SZ8jnAveMD/DQwWGm6w2++sIZ/vbMHI1Vy6aUtUK7B7BdhRAo5GC4WmRyvsFio0m1lCd4I3JJvag8CI16cm5mLt/u0UjSptbXa+VCjt1DFcYGykzOL/P0a1M8e2KaJ+7byaEdfeQ2rOtc40npcSfzbewd7mNppcl0vdHuoUhSe4QAfSPQmE9KpiR1iBDC2sZBYM9QhY89sp+fevcevn9ylj/661OcuFBneaVFK0Z3N6UUuZO5iRAC1VKeajHPTL3B7qEKhZzfdEnqQeXByyUzxqR4SlKHWF+7BWBsoMxHH9rLublkZ7MZI0cPjLBnqEJfKU8uuNaTbpc7mW8jhMBdO/s5M7tEfdlv8CX1qEIluU9m03lQUucLIbBrsMxTR/fy+N07OD61wF+fmOb18/NM1xs0W+5sSrfDncybMDZQSq5QttBgsK+I321J6jm5QvJoeuqApO4QQqCQDxwY7WPPcIW3Zpd488ICJ6frDFSK3LWjys6BMsGdTemWWTJvQj4EHtg7xEqzBRFsmZJ6UmU4OWTWiVBSFwkhUFwvm0MVTs8u8tbsEq+eneP18wsc3lllfLBi2ZRugSXzJoQQ2DdSYbUVPQ1JUm8KAapjUL8AOw5D8GwLSd0lhECxEDi0o8r+kT5m6g0m5xu8ePoicJEH9g6xa6hMbu1iQpJuzJJ5k/K5HHnXVJJ6Wf9OmHkjufCPJHWpEAL5XHKBoJH+EnuHK7w5Xefp16cYrZZ45NAIg5WiO5vSJiyZkqSbUxmC5TlotSDnFWYlda/18pgHhvqKPFAZ4t7xAY5NLvCVF97iwGiFRw6N0l8qXJoKLZzSZZZMSdLNyZeSgtlaBUrtHo0kZW69OOaASjHPA3uHuG/XIC+dmeV/Pn2cI7sHeeyuUQbLhUtHvFk2JUumJOmmBShVk4v/lKrtHowk3TEbi2OpEHjowAj37xni1bNzfOOV8xwY7eOusSpDlSKlQu6a/0bqNZ5lKEm6OSFA/zgsnG/3SCSprUIIVIp53rN/mA8/uJtCPsd3j0/z/JsznJyus7za8j6b6mmWTEnSzRvYA3Nn2z0KSdoWQgj0lws8dGCYJ+4dI5cPHJtc4G9OzvDauXkWG03LpnqSh8tKkm7e4B5orbR7FJK0rYQQGO4r8dihURYaTU5N15laaHBius5otcSR3YNUS3kPoVXPsGRKkm5esQ/G7mv3KCRpWwohMFAucGT3IIuNJmfnlnhrdplv/3CS/aN93Ds+QLmQs2yq61kyJUk3LwQI+XaPQpK2tRACfaU8d431s3e4j9nFBq+dn+dPvv8W79g1wJE9gxRywbKprmXJlCRJklIWQiAA5UKOXYMVxvrLTNcb/L/Xpnj69Sl+7B3j3DPeT96yqS5kyZQkSZIysl4g8znYOVDmZ47uY255lWden+LUTJ0fP7KLvB1TXcaSKUmSJGVsvWyGAEOVAh96cDetViRnwVQXsmRKkiRJd9D6obQ5tzDVpbxPpiRJkiQpNZZMSZIkSVJqLJmSJEmSpNRYMiVJkiRJqbFkSpIkSZJSY8mUJEmSJKXGkilJkiRJSo0lU5IkSZKUGkumJEmSJCk1lkxJkiRJUmosmZIkSZKk1FgyJUmSJEmpsWRKkiRJklJjyZQkSZIkpcaSKUmSJElKjSVTkiRJkpQaS6YkSZIkKTWWTEmSJElSaiyZkiRJkqTUWDIlSZIkSamxZEqSJEmSUhNijOl/aAjngeOpf7A6xV0xxvEsf4EZ63lmTFkzY8qaGVPWzJiydsOMZVIyJUmSJEm9ycNlJUmSJEmpsWRKkiRJklJjyZQkSZIkpabQ7gFsOyE0gRdI/r95GfinxFjf4md9Afi/xPh/NvmZAPxn4KeBOvDPiPHZLf0+dYxQuzZncWJrOQu1JGdx4sY5C7VrcxYnzFlXcy5T1syYsmbGlDHXY9lxJ/Nai8T4MDG+G2gAv3LFuyHkU/59HwHesfb4l8B/SfnztT0txon4cJy4fs5CzZzptjmXKWtmTFkzY8qa67GMuJO5uW8BRwnhSWACOAM8TAjvAf4T8CRQBj5PjL+z9g3Y54APAMeAcBO/42PA75Fc5vdpQhghhL3EeCbt/zHatr4FHA218CQbchZq1+YsTsTfWfsWbEs5ixNJzkItjIRa2BsnzFmPcC5T1syYsmbGlDXXYylyJ/NGQiiQfNvwwtor7wX+PTE+CPxzYJYYHwceBz5JCIeBfwC8E3gP8EngiQ2f91lC+PvX+U37gTc3PD+59pp6QKhdP2dx4nLO4sTlnIXa5jkLtfDZUDNn2sC5TFkzY8qaGVPGXI+lz53Ma/URwnNrf/8W8N9JQvMdYjy29vrfI/k27WfXng+TbHv/OPC/ibEJnCaEP7v0qTF+5ga/73rfenjz0u7XF2rXz1mcuDJnoXb9nMWJJGehdjlnccKc6RLnMmXNjClrZkxZcz2WEUvmtZLj/zcKAWBh4yvAvyXGr1/1cz/NrQflJHBww/MDwOlb/Ax1nsU4cWXOQu36OYsTV+Ys1MyZbopzmbJmxpQ1M6asuR7LiIfLbs3XgV8lhCIAIRwhhH7gm8A/IYQ8IewF3n8Tn/Vl4BcJIRDC+0gO+ei647K1JV8HfjXUkpyFWjgSapdzFmohH2q3lrNQCyHUkpx14/H/umXOZcqaGVPWzJiy5npsC9zJ3Jr/BtwNPLt2Yvl54OPAH5Gc/PsC8CrwjUv/RQifBb5LjF++6rO+SnIZ4x+SXMr4l7IdujrIpZytnVz+tjkLtSRnccKc6aY4lylrZkxZM2PKmuuxLQjJBbQkSZIkSbp9Hi4rSZIkSUqNJVOSJEmSlBpLpiRJkiQpNZZMSZIkSVJqLJmSJEmSpNRYMiVJkiRJqbFkSpIkSZJS8/8BSyR8CsmCvDcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowTestImages(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    test(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1826,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[100,64,300,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_125/mobilenet_1.00_224/conv_pw_1/Conv2D (defined at <ipython-input-1823-1a16278d3c0f>:7) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_4515310]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1826-30890e9ba34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m _ = model.fit(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Abrar/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[100,64,300,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_125/mobilenet_1.00_224/conv_pw_1/Conv2D (defined at <ipython-input-1823-1a16278d3c0f>:7) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_4515310]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    lr *= 0.2\n",
    "  return max(lr, 3e-7)\n",
    "\n",
    "\n",
    "_ = model.fit(\n",
    "    data_generator(batch_size=100),\n",
    "    use_multiprocessing=True,\n",
    "    workers=5,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=500,\n",
    "    callbacks=[\n",
    "               ShowTestImages(),\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='line_out', patience=3, mode='max'),\n",
    "               tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Object Localization with TensorFlow - Starter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
